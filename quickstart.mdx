---
title: "Quickstart"
description: "Get started with LemonData API in 2 minutes"
---

## Step 1: Get Your API Key

<Steps>
  <Step title="Create an account">
    Sign up at [lemondata.cc](https://lemondata.cc) using your email.
  </Step>
  <Step title="Add credits">
    Navigate to the dashboard and add credits to your account. Pay-as-you-go pricing with no minimum.
  </Step>
  <Step title="Create API key">
    Go to **Dashboard â†’ API Keys** and create a new key. Copy it securely - it's only shown once.
  </Step>
</Steps>

<Warning>
  Keep your API key secure. Never expose it in client-side code or public repositories.
</Warning>

## Step 2: Install SDK

<CodeGroup>

```bash Python
pip install openai
```

```bash JavaScript
npm install openai
```

```bash Go
go get github.com/sashabaranov/go-openai
```

```bash PHP
composer require openai-php/client
```

</CodeGroup>

## Step 3: Make Your First Request

<CodeGroup>

```bash cURL
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is the capital of France?"}
    ]
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ]
)

print(response.choices[0].message.content)
# Output: The capital of France is Paris.
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'What is the capital of France?' }
  ]
});

console.log(response.choices[0].message.content);
// Output: The capital of France is Paris.
```

```go Go
package main

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("sk-your-api-key")
    config.BaseURL = "https://api.lemondata.cc/v1"

    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "gpt-4o",
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleSystem, Content: "You are a helpful assistant."},
                {Role: openai.ChatMessageRoleUser, Content: "What is the capital of France?"},
            },
        },
    )
    if err != nil {
        panic(err)
    }
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/chat/completions');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'messages' => [
            ['role' => 'system', 'content' => 'You are a helpful assistant.'],
            ['role' => 'user', 'content' => 'What is the capital of France?']
        ]
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['choices'][0]['message']['content'];
// Output: The capital of France is Paris.
```

</CodeGroup>

## Try Different Models

LemonData supports 300+ models. Just change the `model` parameter:

```python
# OpenAI GPT-4o
response = client.chat.completions.create(model="gpt-4o", messages=messages)

# Anthropic Claude Sonnet 4.5
response = client.chat.completions.create(model="claude-sonnet-4-5", messages=messages)

# Google Gemini 2.5 Flash
response = client.chat.completions.create(model="gemini-2.5-flash", messages=messages)

# DeepSeek R1
response = client.chat.completions.create(model="deepseek-r1", messages=messages)
```

## Enable Streaming

For real-time responses, enable streaming:

```python
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

## What's Next?

<CardGroup cols={2}>
  <Card title="Authentication" icon="key" href="/authentication">
    Learn about API key management and security.
  </Card>
  <Card title="Models" icon="robot" href="https://lemondata.cc/en/models">
    Explore all available models and their capabilities.
  </Card>
  <Card title="Streaming" icon="bolt" href="/guides/streaming">
    Implement real-time streaming responses.
  </Card>
  <Card title="Error Handling" icon="triangle-exclamation" href="/guides/error-handling">
    Handle errors gracefully in your application.
  </Card>
</CardGroup>
