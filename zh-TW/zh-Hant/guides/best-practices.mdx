```mdx
---
title: "最佳實踐"
description: "優化您的 LemonData API 使用，以提升成本效益、效能與可靠性"
---

## 模型選擇

選擇合適的模型會顯著影響成本與品質。

### 基於任務的建議

| 任務 | 推薦模型 | 原因 |
|------|-------------------|-----------|
| **簡單問答** | `gpt-4o-mini`, `gemini-2.5-flash` | 快速、便宜、足夠好用 |
| **複雜推理** | `o3`, `claude-opus-4-5`, `deepseek-r1` | 更好的邏輯與規劃能力 |
| **程式編寫** | `claude-sonnet-4-5`, `gpt-4o`, `deepseek-v3.2` | 針對程式碼優化 |
| **創意寫作** | `claude-sonnet-4-5`, `gpt-4o` | 更好的散文品質 |
| **視覺/圖像** | `gpt-4o`, `claude-sonnet-4-5`, `gemini-2.5-flash` | 原生視覺支援 |
| **長上下文** | `gemini-2.5-pro`, `claude-sonnet-4-5` | 1M+ token 視窗 |
| **成本敏感** | `gpt-4o-mini`, `gemini-2.5-flash`, `deepseek-v3.2` | 最佳性價比 |

### 成本分級

```
$$$$ Premium: o3, claude-opus-4-5, gpt-4o
$$$  Standard: claude-sonnet-4-5, gpt-4o
$$   Budget:   gpt-4o-mini, gemini-2.5-flash
$    Economy:  deepseek-v3.2, deepseek-r1
```

## 成本優化

### 1. 優先使用小型模型

```python
def smart_query(question: str, complexity: str = "auto"):
    """Use cheaper models for simple tasks."""

    if complexity == "simple":
        model = "gpt-4o-mini"
    elif complexity == "complex":
        model = "gpt-4o"
    else:
        # Start cheap, escalate if needed
        model = "gpt-4o-mini"

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": question}]
    )
    return response
```

### 2. 設定 max_tokens

務必設定合理的 `max_tokens` 限制：

```python
# ❌ 錯誤：未設限制，可能會產生數千個 token
response = client.chat.completions.create(
    model="gpt-