---
title: "Crear respuesta"
openapi: "POST /v1/responses"
description: "Crea una respuesta utilizando el formato de la API de OpenAI Responses"
---

La API de Responses es la API de conversación con estado más reciente de OpenAI. LemonData ofrece soporte para este formato en modelos compatibles.

## Cuerpo de la solicitud

<ParamField body="model" type="string" required>
  El ID del modelo a utilizar. Consulta [Models](https://lemondata.cc/zh-TW/models) para ver las opciones disponibles.
</ParamField>

<ParamField body="input" type="array" required>
  Lista de elementos de entrada que componen la conversación.

  Cada elemento puede ser:
  - `message`: un mensaje de conversación que contiene el rol y el contenido
  - `function_call`: una solicitud de llamada a función
  - `function_call_output`: el resultado de una llamada a función
</ParamField>

<ParamField body="instructions" type="string">
  Instrucciones del sistema para el modelo (equivalente al mensaje del sistema).
</ParamField>

<ParamField body="max_output_tokens" type="integer">
  El número máximo de tokens a generar.
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Temperatura de muestreo entre 0 y 2.
</ParamField>

<ParamField body="tools" type="array">
  Lista de herramientas que el modelo puede llamar.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Si es true, devuelve un flujo de eventos.
</ParamField>

<ParamField body="previous_response_id" type="string">
  ID de la respuesta anterior, utilizado para continuar la conversación.
</ParamField>

<ParamField body="store" type="boolean" default="true">
  Si se debe guardar la respuesta para su recuperación posterior.
</ParamField>

<ParamField body="metadata" type="object">
  Metadatos adjuntos a la respuesta para fines de seguimiento.
</ParamField>

<ParamField body="text" type="object">
  Opciones de configuración para la generación de texto.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  Si se permite realizar múltiples llamadas a herramientas de forma simultánea.
</ParamField>

<ParamField body="top_p" type="number">
  Parámetro de muestreo de núcleo (0-1).
</ParamField>

<ParamField body="reasoning" type="object">
  Configuración de razonamiento para los modelos o1/o3.

  - `effort` (string): nivel de intensidad del razonamiento (`low`, `medium`, `high`)
</ParamField>

## Respuesta

<ResponseField name="id" type="string">
  Identificador único de la respuesta.
</ResponseField>

<ResponseField name="object" type="string">
  Fijado como `response`.
</ResponseField>

<ResponseField name="created_at" type="integer">
  Marca de tiempo Unix de cuando se creó la respuesta.
</ResponseField>

<ResponseField name="output" type="array">
  Lista de elementos de salida generados por el modelo.
</ResponseField>

<ResponseField name="usage" type="object">
  Estadísticas de uso de tokens.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/responses" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"type": "message", "role": "user", "content": "Hello!"}
    ],
    "max_output_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.responses.create(
    model="gpt-4o",
    input=[
        {"type": "message", "role": "user", "content": "Hello!"}
    ],
    max_output_tokens=1000
)

print(response.output)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.responses.create({
  model: 'gpt-4o',
  input: [
    { type: 'message', role: 'user', content: 'Hello!' }
  ],
  max_output_tokens: 1000
});

console.log(response.output);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model": "gpt-4o",
        "input": []map[string]interface{}{
            {"type": "message", "role": "user", "content": "Hello!"},
        },
        "max_output_tokens": 1000,
    }
    body, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/responses", bytes.NewBuffer(body))
    req.Header.Set("Authorization", "Bearer sk-your-api-key")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["output"])
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/responses');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'input' => [
            ['type' => 'message', 'role' => 'user', 'content' => 'Hello!']
        ],
        'max_output_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
print_r($data['output']);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "resp_abc123",
  "object": "response",
  "created_at": 1706000000,
  "model": "gpt-4o",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "Hello! How can I help you today?"}
      ]
    }
  ],
  "usage": {
    "input_tokens": 10,
    "output_tokens": 12,
    "total_tokens": 22
  }
}
```
</ResponseExample>