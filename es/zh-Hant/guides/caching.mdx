---
title: "✨ Cache Inteligente"
description: "Reduzca costos y latencia mediante el cache semántico consciente del contexto"
---

## Resumen

LemonData ofrece un sistema de cache inteligente que reduce significativamente sus costos de API y la latencia de respuesta. Nuestro cache va más allá de la simple coincidencia de solicitudes; comprende el **significado semántico (semantic meaning)** de sus prompts.

<CardGroup cols={2}>
  <Card title="Ahorro de costos" icon="piggy-bank">
    Los cache hits se facturan a una fracción del costo normal.
  </Card>
  <Card title="Respuestas más rápidas" icon="bolt">
    Las respuestas en cache se devuelven instantáneamente sin necesidad de inferencia del modelo.
  </Card>
  <Card title="Consciente del contexto" icon="brain">
    La coincidencia semántica encuentra solicitudes similares incluso cuando la redacción es diferente.
  </Card>
  <Card title="Control de privacidad" icon="shield">
    Control total sobre qué se almacena en cache y qué se comparte.
  </Card>
</CardGroup>

## Cómo funciona

LemonData utiliza un sistema de cache de dos capas:

### Capa 1: Cache de respuesta (Coincidencia exacta)

Para solicitudes deterministas (`temperature=0`), almacenamos en cache la respuesta exacta:

- **Condiciones de coincidencia**: Mismo modelo, mensajes y parámetros
- **Velocidad**: Instantánea (nivel de microsegundos)
- **Ideal para**: Consultas idénticas repetidas

### Capa 2: Cache semántico (Coincidencia por similitud)

Para todas las solicitudes, también verificamos la similitud semántica utilizando un algoritmo de coincidencia de dos etapas:

- **Etapa 1 (Solo consulta)**: Similitud de la consulta del usuario ≥95%
- **Etapa 2 (Contexto completo)**: Similitud incluyendo el contexto de la conversación ≥85%
- **Ideal para**: Consultas tipo FAQ, preguntas frecuentes

```
User A: "What is the capital of France?"
User B: "Tell me the capital city of France"
→ Same cached response (high semantic similarity)
```

## Control de cache

### Control a nivel de solicitud

Utilice el parámetro `cache_control` en el cuerpo de la solicitud para controlar el comportamiento del cache en cada solicitud:

```bash
# 跳過快取查詢，始終呼叫模型
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}],
    "cache_control": {"type": "no_cache"}
  }'
```

