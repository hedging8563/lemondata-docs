---
title: "Démarrage rapide"
description: "Prenez en main l'API LemonData en moins de 2 minutes"
---

## Étape 1 : Obtenir votre API Key

<Steps>
  <Step title="Créer un compte">
    Inscrivez-vous sur [lemondata.cc](https://lemondata.cc). La connexion via e-mail, Gmail ou GitHub est supportée.
  </Step>
  <Step title="Recharger votre crédit">
    Accédez au tableau de bord et rechargez votre compte. Modèle de tarification à l'usage, sans consommation minimale requise.
  </Step>
  <Step title="Créer une API Key">
    Allez dans **Dashboard → API Keys** et créez une nouvelle clé. Veuillez la copier et la conserver en lieu sûr — elle ne sera affichée qu'une seule fois.
  </Step>
</Steps>

<Warning>
  Veuillez conserver votre API Key en toute sécurité. Ne l'exposez jamais dans le code côté client ou dans des dépôts de code publics.
</Warning>

## Étape 2 : Installer le SDK

<CodeGroup>

```bash Python
pip install openai
```

```bash JavaScript
npm install openai
```

```bash Go
go get github.com/sashabaranov/go-openai
```

```bash PHP
composer require openai-php/client
```

</CodeGroup>

## Étape 3 : Envoyer votre première requête

<CodeGroup>

```bash cURL
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is the capital of France?"}
    ]
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ]
)

print(response.choices[0].message.content)
# Output: The capital of France is Paris.
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'What is the capital of France?' }
  ]
});

console.log(response.choices[0].message.content);
// Output: The capital of France is Paris.
```

```go Go
package main

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("sk-your-api-key")
    config.BaseURL = "https://api.lemondata.cc/v1"

    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "gpt-4o",
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleSystem, Content: "You are a helpful assistant."},
                {Role: openai.ChatMessageRoleUser, Content: "What is the capital of France?"},
            },
        },
    )
    if err != nil {
        panic(err)
    }
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/chat/completions');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'messages' => [
            ['role' => 'system', 'content' => 'You are a helpful assistant.'],
            ['role' => 'user', 'content' => 'What is the capital of France?']
        ]
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['choices'][0]['message']['content'];
// Output: The capital of France is Paris.
```

</CodeGroup>

## Essayer différents modèles

LemonData supporte plus de 300 modèles. Il suffit de modifier le paramètre `model` :

```python
# OpenAI GPT-4o
response = client.chat.completions.create(model="gpt-4o", messages=messages)

# Anthropic Claude Sonnet 4.5
response = client.chat.completions.create(model="claude-sonnet-4-5", messages=messages)

# Google Gemini 2.5 Flash
response = client.chat.completions.create(model="gemini-2.5-flash", messages=messages)

# DeepSeek R1
response = client.chat.completions.create(model="deepseek-r1", messages=messages)
```

## Activer le streaming

Pour des réponses en temps réel, activez le streaming :

```python
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

## Prochaines étapes ?

<CardGroup cols={2}>
  <Card title="Authentification" icon="key" href="/authentication">
    En savoir plus sur la gestion et la sécurité des API Keys.
  </Card>
  <Card title="Modèles" icon="robot" href="https://lemondata.cc/zh-TW/models">
    Explorez tous les modèles disponibles et leurs fonctionnalités.
  </Card>
  <Card title="Streaming" icon="bolt" href="/guides/streaming">
    Implémentez des réponses en streaming en temps réel.
  </Card>
  <Card title="Gestion des erreurs" icon="triangle-exclamation" href="/guides/error-handling">
    Gérez les erreurs avec élégance dans votre application.
  </Card>
</CardGroup>