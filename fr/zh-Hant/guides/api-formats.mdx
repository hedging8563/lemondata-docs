---
title: "✨ API Multi-format"
description: "Utilisez les formats OpenAI, Anthropic ou Gemini avec une seule API key"
---

## Aperçu

LemonData prend en charge **trois formats d'API natifs** via une seule API key. Choisissez le format qui convient le mieux à votre cas d'utilisation — aucun changement de configuration n'est requis.

<CardGroup cols={3}>
  <Card title="Format OpenAI" icon="plug">
    `/v1/chat/completions`
    Format standard, compatibilité la plus large
  </Card>
  <Card title="Format Anthropic" icon="message">
    `/v1/messages`
    Pensée étendue, fonctionnalités Claude natives
  </Card>
  <Card title="Format Gemini" icon="sparkles">
    `/v1beta/models/:model:generateContent`
    Intégration de l'écosystème Google
  </Card>
</CardGroup>

## Pourquoi utiliser le multi-format ?

| Avantage | Description |
|---------|-------------|
| **Pas de changement de SDK** | Appelez n'importe quel modèle en utilisant votre SDK préféré |
| **Fonctionnalités natives** | Accédez aux fonctionnalités spécifiques à chaque format |
| **Migration facile** | Passez des API officielles en changeant simplement la base URL |
| **Facturation unifiée** | Un compte, une API key, prise en charge de tous les formats |

## Comparaison des formats

| Fonctionnalité | OpenAI | Anthropic | Gemini |
|---------|--------|-----------|--------|
| **Endpoint** | `/v1/chat/completions` | `/v1/messages` | `/v1beta/models/:model:generateContent` |
| **En-tête d'authentification** | `Authorization: Bearer` | `x-api-key` | `Authorization: Bearer` |
| **System Prompt** | Dans le tableau `messages` | Champ `system` indépendant | Dans `systemInstruction` |
| **Pensée étendue** | ❌ | ✅ | ❌ |
| **Streaming** | ✅ SSE | ✅ SSE | ✅ SSE |
| **Appel d'outils** | ✅ | ✅ | ✅ |
| **Vision** | ✅ | ✅ | ✅ |

## Format OpenAI

Le format avec la compatibilité la plus large. Fonctionne avec tous les modèles LemonData.

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-lemondata-key",
    base_url="https://api.lemondata.cc/v1"
)

# Fonctionne pour n'importe quel modèle
response = client.chat.completions.create(
    model="claude-sonnet-4-5",  # Appel de Claude via le format OpenAI
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
```

**Idéal pour :**
- Usage général
- Intégrations existantes du SDK OpenAI
- Compatibilité maximale

## Format Anthropic

API Messages Anthropic native. Indispensable pour utiliser les fonctionnalités spécifiques à Claude (comme la pensée étendue).

```python
from anthropic import Anthropic

client = Anthropic(
    api_key="sk-your-lemondata-key",
    base_url="https://api.lemondata.cc"  # Pas de suffixe /v1 requis !
)

message = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    system="You are a helpful assistant.",  # Champ system indépendant
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)
```

### Pensée étendue (Claude Opus 4.5)

Disponible uniquement au format Anthropic :

```python
message = client.messages.create(
    model="claude-opus-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    messages=[{"role": "user", "content": "Solve this complex problem..."}]
)

# Accéder au processus de réflexion
for block in message.content:
    if block.type == "thinking":
        print(f"Thinking: {block.thinking}")
    elif block.type == "text":
        print(f"Answer: {block.text}")
```

**Idéal pour :**
- Fonctionnalités spécifiques à Claude
- Mode pensée étendue (Extended Thinking)
- Utilisateurs du SDK Anthropic natif

## Format Gemini

Format d'API Google Gemini natif, pour l'intégration de l'écosystème Google.

```bash
curl "https://api.lemondata.cc/v1beta/models/gemini-2.5-flash:generateContent" \
  -H "Authorization: Bearer sk-your-lemondata-key" \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{
      "parts": [{"text": "Hello!"}]
    }],
    "systemInstruction": {
      "parts": [{"text": "You are a helpful assistant."}]
    }
  }'
```

### Streaming

```bash
curl "https://api.lemondata.cc/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse" \
  -H "Authorization: Bearer sk-your-lemondata-key" \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{"parts": [{"text": "Write a story"}]}]
  }'
```

**Idéal pour :**
- Intégration Google Cloud
- Code SDK Gemini existant
- Fonctionnalités Gemini natives

## Choisir le bon format

```mermaid
graph TD
    A[Quel format choisir ?] --> B{Besoin de la pensée étendue Claude ?}
    B -->|Oui| C[Utiliser le format Anthropic]
    B -->|Non| D{Base de code existante ?}
    D -->|SDK OpenAI| E[Utiliser le format OpenAI]
    D -->|SDK Anthropic| C
    D -->|SDK Gemini| F[Utiliser le format Gemini]
    D -->|Nouveau projet| E
```

## Guide de migration

### Migration depuis l'API officielle OpenAI

```python
# Avant migration (OpenAI)
client = OpenAI(api_key="sk-openai-key")

# Après migration (LemonData)
client = OpenAI(
    api_key="sk-lemondata-key",
    base_url="https://api.lemondata.cc/v1"  # Ajoutez cette ligne
)
# C'est tout ! Le même code fonctionne
```

### Migration depuis l'API officielle Anthropic

```python
# Avant migration (Anthropic)
client = Anthropic(api_key="sk-ant-key")

# Après migration (LemonData)
client = Anthropic(
    api_key="sk-lemondata-key",
    base_url="https://api.lemondata.cc"  # Ajoutez cette ligne (pas de /v1 !)
)
```

### Migration depuis Google AI Studio

```python
# Avant migration (Google)
import google.generativeai as genai
genai.configure(api_key="google-api-key")

# Après migration (LemonData) - Utilisation de l'API REST
import requests

response = requests.post(
    "https://api.lemondata.cc/v1beta/models/gemini-2.5-flash:generateContent",
    headers={"Authorization": "Bearer sk-lemondata-key"},
    json={"contents": [{"parts": [{"text": "Hello"}]}]}
)
```

## Compatibilité cross-modèle

La magie de LemonData : utilisez **n'importe quel SDK** avec **n'importe quel modèle**. La passerelle gère automatiquement la conversion de format.

### N'importe quel SDK → N'importe quel modèle

```python
# Appel de GPT-4o avec le SDK Anthropic (converti automatiquement au format OpenAI)
from anthropic import Anthropic

client = Anthropic(
    api_key="sk-lemondata-key",
    base_url="https://api.lemondata.cc"
)

response = client.messages.create(
    model="gpt-4o",  # ✅ Fonctionne ! Converti automatiquement
    max_tokens=1024,
    messages=[{"role": "user", "content": "Hello!"}]
)

# Même SDK, modèles différents — aucun changement de code
response = client.messages.create(model="gemini-2.5-flash", ...)  # ✅ Fonctionne !
response = client.messages.create(model="deepseek-r1", ...)       # ✅ Fonctionne !
```

### SDK OpenAI → Tous les modèles

```python
from openai import OpenAI

client = OpenAI(base_url="https://api.lemondata.cc/v1", api_key="sk-...")

# Les modèles suivants fonctionnent tous avec le même SDK :
response = client.chat.completions.create(model="gpt-4o", ...)
response = client.chat.completions.create(model="claude-sonnet-4-5", ...)
response = client.chat.completions.create(model="gemini-2.5-flash", ...)
```

### Comparaison avec l'industrie

| Plateforme | Format OpenAI | Format Anthropic | Format Gemini | API Responses |
|----------|:---:|:---:|:---:|:---:|
| **LemonData** | ✅ Tous les modèles | ✅ Tous les modèles | ✅ Tous les modèles | ✅ Tous les modèles |
| OpenRouter | ✅ Tous les modèles | ❌ | ❌ | ❌ |
| Together AI | ✅ Tous les modèles | ❌ | ❌ | ❌ |
| Fireworks | ✅ Tous les modèles | ❌ | ❌ | ❌ |

<Note>
Bien que le support cross-format prenne en charge la plupart des fonctionnalités, les fonctionnalités spécifiques à un format (comme la pensée étendue d'Anthropic) nécessitent toujours l'utilisation du format natif.
</Note>