---
title: "Créer une réponse"
openapi: "POST /v1/responses"
description: "Créer une réponse en utilisant le format de l'API OpenAI Responses"
---

L'API Responses est une API de conversation avec état plus récente d'OpenAI. LemonData prend en charge ce format pour les modèles compatibles.

## Corps de la requête

<ParamField body="model" type="string" required>
  L'ID du modèle à utiliser. Veuillez consulter [Models](https://lemondata.cc/zh-TW/models) pour voir les options disponibles.
</ParamField>

<ParamField body="input" type="array" required>
  Liste des éléments d'entrée composant la conversation.

  Chaque élément peut être :
  - `message` : un message de conversation contenant un rôle et un contenu
  - `function_call` : une requête d'appel de fonction
  - `function_call_output` : la sortie d'un appel de fonction
</ParamField>

<ParamField body="instructions" type="string">
  Instructions système pour le modèle (équivalent au message système).
</ParamField>

<ParamField body="max_output_tokens" type="integer">
  Le nombre maximum de tokens à générer.
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Température d'échantillonnage comprise entre 0 et 2.
</ParamField>

<ParamField body="tools" type="array">
  Liste des outils que le modèle peut appeler.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Si true, renvoie un flux d'événements.
</ParamField>

<ParamField body="previous_response_id" type="string">
  L'ID de la réponse précédente, utilisé pour poursuivre la conversation.
</ParamField>

<ParamField body="store" type="boolean" default="true">
  Indique s'il faut stocker la réponse pour une récupération ultérieure.
</ParamField>

<ParamField body="metadata" type="object">
  Métadonnées attachées à la réponse, utilisées à des fins de suivi.
</ParamField>

<ParamField body="text" type="object">
  Options de configuration de la génération de texte.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  Indique s'il faut autoriser plusieurs appels d'outils simultanés.
</ParamField>

<ParamField body="top_p" type="number">
  Paramètre d'échantillonnage nucléaire (0-1).
</ParamField>

<ParamField body="reasoning" type="object">
  Configuration du raisonnement pour les modèles o1/o3.

  - `effort` (string) : niveau d'intensité du raisonnement (`low`, `medium`, `high`)
</ParamField>

## Réponse

<ResponseField name="id" type="string">
  Identifiant unique de la réponse.
</ResponseField>

<ResponseField name="object" type="string">
  Fixé à `response`.
</ResponseField>

<ResponseField name="created_at" type="integer">
  Horodatage Unix de la création de la réponse.
</ResponseField>

<ResponseField name="output" type="array">
  Liste des éléments de sortie générés par le modèle.
</ResponseField>

<ResponseField name="usage" type="object">
  Statistiques d'utilisation des tokens.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/responses" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"type": "message", "role": "user", "content": "Hello!"}
    ],
    "max_output_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.responses.create(
    model="gpt-4o",
    input=[
        {"type": "message", "role": "user", "content": "Hello!"}
    ],
    max_output_tokens=1000
)

print(response.output)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.responses.create({
  model: 'gpt-4o',
  input: [
    { type: 'message', role: 'user', content: 'Hello!' }
  ],
  max_output_tokens: 1000
});

console.log(response.output);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model": "gpt-4o",
        "input": []map[string]interface{}{
            {"type": "message", "role": "user", "content": "Hello!"},
        },
        "max_output_tokens": 1000,
    }
    body, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/responses", bytes.NewBuffer(body))
    req.Header.Set("Authorization", "Bearer sk-your-api-key")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["output"])
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/responses');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'input' => [
            ['type' => 'message', 'role' => 'user', 'content' => 'Hello!']
        ],
        'max_output_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
print_r($data['output']);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "resp_abc123",
  "object": "response",
  "created_at": 1706000000,
  "model": "gpt-4o",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "Hello! How can I help you today?"}
      ]
    }
  ],
  "usage": {
    "input_tokens": 10,
    "output_tokens": 12,
    "total_tokens": 22
  }
}
```
</ResponseExample>