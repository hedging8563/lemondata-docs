---
title: "Créer un message"
api: "POST /v1/messages"
description: "Crée un message en utilisant le format de l'API Anthropic Messages"
---

## Aperçu

Cet endpoint offre une compatibilité native avec l'API Anthropic Messages. Utilisez-le pour les modèles Claude avec des fonctionnalités telles que la réflexion étendue (extended thinking).

<Note>
URL de base pour le SDK Anthropic : `https://api.lemondata.cc` (pas de suffixe `/v1`)
</Note>

## En-têtes de requête

<ParamField header="x-api-key" type="string" required>
  Votre clé API LemonData. Alternative au token Bearer.
</ParamField>

<ParamField header="anthropic-version" type="string" required>
  Version de l'API Anthropic. Utilisez `2023-06-01`.
</ParamField>

## Corps de la requête

<ParamField body="model" type="string" required>
  ID du modèle Claude (ex: `claude-sonnet-4-5`).
</ParamField>

<ParamField body="messages" type="array" required>
  Tableau d'objets de message avec `role` et `content`.
</ParamField>

<ParamField body="max_tokens" type="integer" required>
  Nombre maximum de tokens à générer.
</ParamField>

<ParamField body="system" type="string">
  Prompt système (séparé du tableau `messages`).
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Température d'échantillonnage (0-1).
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Activer les réponses en streaming.
</ParamField>

<ParamField body="thinking" type="object">
  Configuration de la réflexion étendue (Claude Opus 4.5).

  - `type` (string) : `"enabled"` pour activer
  - `budget_tokens` (integer) : Budget de tokens pour la réflexion
</ParamField>

<ParamField body="tools" type="array">
  Outils disponibles pour le modèle.
</ParamField>

<ParamField body="tool_choice" type="object">
  Comment le modèle doit utiliser les outils. Options : `auto`, `any`, `tool` (outil spécifique).
</ParamField>

<ParamField body="top_p" type="number">
  Paramètre d'échantillonnage nucleus. Utilisez soit `temperature` soit `top_p`, mais pas les deux.
</ParamField>

<ParamField body="top_k" type="integer">
  Échantillonner uniquement parmi les `K` meilleures options pour chaque token.
</ParamField>

<ParamField body="stop_sequences" type="array">
  Séquences d'arrêt personnalisées qui forceront le modèle à arrêter la génération.
</ParamField>

<ParamField body="metadata" type="object">
  Métadonnées à joindre à la requête à des fins de suivi.
</ParamField>

## Réponse

<ResponseField name="id" type="string">
  Identifiant unique du message.
</ResponseField>

<ResponseField name="type" type="string">
  Toujours `message`.
</ResponseField>

<ResponseField name="role" type="string">
  Toujours `assistant`.
</ResponseField>

<ResponseField name="content" type="array">
  Tableau de blocs de contenu (`text`, `thinking`, `tool_use`).
</ResponseField>

<ResponseField name="model" type="string">
  Modèle utilisé.
</ResponseField>

<ResponseField name="stop_reason" type="string">
  Raison pour laquelle la génération s'est arrêtée (`end_turn`, `max_tokens`, `tool_use`).
</ResponseField>

<ResponseField name="usage" type="object">
  Utilisation des tokens avec `input_tokens` et `output_tokens`.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/messages" \
  -H "x-api-key: sk-your-api-key" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "system": "You are a helpful assistant.",
    "messages": [
      {"role": "user", "content": "Hello, Claude!"}
    ]
  }'
```

```python Python
from anthropic import Anthropic

client = Anthropic(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc"
)

message = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    system="You are a helpful assistant.",
    messages=[
        {"role": "user", "content": "Hello, Claude!"}
    ]
)

print(message.content[0].text)
```

```javascript JavaScript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc'
});

const message = await client.messages.create({
  model: 'claude-sonnet-4-5',
  max_tokens: 1024,
  system: 'You are a helpful assistant.',
  messages: [
    { role: 'user', content: 'Hello, Claude!' }
  ]
});

console.log(message.content[0].text);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model":      "claude-sonnet-4-5",
        "max_tokens": 1024,
        "system":     "You are a helpful assistant.",
        "messages": []map[string]string{
            {"role": "user", "content": "Hello, Claude!"},
        },
    }

    jsonData, _ := json.Marshal(payload)
    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/messages", bytes.NewBuffer(jsonData))
    req.Header.Set("x-api-key", "sk-your-api-key")
    req.Header.Set("anthropic-version", "2023-06-01")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    body, _ := io.ReadAll(resp.Body)
    fmt.Println(string(body))
}
```

```php PHP
<?php
$payload = [
    'model' => 'claude-sonnet-4-5',
    'max_tokens' => 1024,
    'system' => 'You are a helpful assistant.',
    'messages' => [
        ['role' => 'user', 'content' => 'Hello, Claude!']
    ]
];

$ch = curl_init('https://api.lemondata.cc/v1/messages');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'x-api-key: sk-your-api-key',
        'anthropic-version: 2023-06-01',
        'Content-Type: application/json'
    ],
    CURLOPT_POSTFIELDS => json_encode($payload)
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['content'][0]['text'];
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "msg_abc123",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you today?"
    }
  ],
  "model": "claude-sonnet-4-5",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 15,
    "output_tokens": 10
  }
}
```
</ResponseExample>

## Exemple de réflexion étendue (Extended Thinking)

```python
message = client.messages.create(
    model="claude-opus-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    messages=[{"role": "user", "content": "Solve this math problem..."}]
)

for block in message.content:
    if block.type == "thinking":
        print(f"Thinking: {block.thinking}")
    elif block.type == "text":
        print(f"Response: {block.text}")
```