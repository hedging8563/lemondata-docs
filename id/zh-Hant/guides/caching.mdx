---
title: "✨ Cache Pintar"
description: "Kurangi biaya dan latensi dengan cache semantik yang sadar konteks"
---

## Ringkasan

LemonData menyediakan sistem cache pintar yang secara signifikan mengurangi biaya API dan latensi respons Anda. Cache kami bukan sekadar pencocokan permintaan sederhana; sistem ini memahami **makna semantik (semantic meaning)** dari prompt Anda.

<CardGroup cols={2}>
  <Card title="Hemat Biaya" icon="piggy-bank">
    Cache hit hanya dikenakan biaya sebagian kecil dari biaya normal.
  </Card>
  <Card title="Respons Lebih Cepat" icon="bolt">
    Respons yang di-cache akan dikirimkan secara instan tanpa perlu melakukan inferensi model.
  </Card>
  <Card title="Sadar Konteks" icon="brain">
    Pencocokan semantik menemukan permintaan serupa bahkan jika kata-katanya berbeda.
  </Card>
  <Card title="Kontrol Privasi" icon="shield">
    Kontrol penuh atas apa yang di-cache dan dibagikan.
  </Card>
</CardGroup>

## Cara Kerja

LemonData menggunakan sistem cache dua lapis:

### Lapisan 1: Cache Respons (Pencocokan Persis)

Untuk permintaan deterministik (`temperature=0`), kami menyimpan cache respons yang persis:

- **Kriteria Pencocokan**: Model, pesan, dan parameter yang sama
- **Kecepatan**: Instan (level mikrodetik)
- **Cocok untuk**: Kueri identik yang berulang

### Lapisan 2: Cache Semantik (Pencocokan Kemiripan)

Untuk semua permintaan, kami juga memeriksa kemiripan semantik menggunakan algoritma pencocokan dua tahap:

- **Tahap 1 (Hanya Kueri)**: Kemiripan kueri pengguna ≥95%
- **Tahap 2 (Konteks Lengkap)**: Kemiripan termasuk konteks percakapan ≥85%
- **Cocok untuk**: Kueri tipe FAQ, pertanyaan umum

```
User A: "What is the capital of France?"
User B: "Tell me the capital city of France"
→ Same cached response (high semantic similarity)
```

## Kontrol Cache

### Kontrol Tingkat Permintaan

Gunakan parameter `cache_control` dalam body permintaan untuk mengontrol perilaku cache pada setiap permintaan:

```bash
# Lewati pencarian cache, selalu panggil model
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}],
    "cache_control": {"type": "no_cache"}
  }'
```

| Tipe | Efek |
|------|------|
| `no_cache` | Lewati pencarian cache, selalu ambil respons baru |
| `no_store` | Jangan simpan respons ini ke dalam cache |
| `response_only` | Hanya gunakan cache pencocokan persis (lewati cache semantik) |
| `semantic_only` | Hanya gunakan cache semantik (lewati pencocokan persis) |

### Header Respons

Setiap respons menyertakan status cache:

```
X-Cache-Status: HIT    # Respons berasal dari cache
X-Cache-Status: MISS   # Respons baru dari model
```

## Memeriksa Status Cache

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What is 2+2?"}]
)

# Periksa status cache dari header respons
# (Tersedia dalam respons HTTP mentah)
print(f"Cache: {response._raw_response.headers.get('X-Cache-Status')}")
```

## Penagihan Cache

Biaya untuk cache hit secara signifikan lebih rendah daripada permintaan baru:

| Tipe | Biaya |
|------|------|
| Cache Hit (HIT) | **Diskon 90% (Bayar 10%)** |
| Cache Miss (MISS) | Harga asli |

Diskon yang tepat ditampilkan dalam log penggunaan dashboard Anda.

## Kontrol Privasi

### Tingkat Organisasi / Pengguna

Konfigurasikan perilaku cache di pengaturan dashboard:

| Mode | Deskripsi |
|------|-------------|
| **Shared** | Cache diaktifkan, respons dapat dibagikan antar pengguna (default untuk akun personal) |
| **Isolated** | Cache diaktifkan, tetapi respons terbatas hanya untuk organisasi Anda (default untuk akun organisasi) |
| **Disabled** | Tidak menggunakan cache sama sekali |

Item lain yang dapat dikonfigurasi:
- **Ambang Kemiripan**: Sesuaikan sensitivitas pencocokan semantik (default: 92%)
- **TTL Kustom**: Menimpa waktu kedaluwarsa cache
- **Pengecualian Model**: Nonaktifkan cache untuk model tertentu

### Tingkat Permintaan

Gunakan parameter `cache_control` untuk menimpa pengaturan pada satu permintaan:

```bash
# Nonaktifkan cache untuk permintaan ini
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "..."}],
    "cache_control": {"type": "no_store"}
  }'
```

## Umpan Balik Cache

Jika Anda menerima respons cache yang salah, Anda dapat melaporkannya:

```bash
curl -X POST https://api.lemondata.cc/v1/cache/feedback \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{
    "cache_entry_id": "abc123",
    "feedback_type": "wrong_answer",
    "description": "Response was outdated"
  }'
```

**Tipe Umpan Balik:**
- `wrong_answer` - Kesalahan faktual
- `outdated` - Informasi sudah usang
- `irrelevant` - Tidak relevan dengan pertanyaan
- `other` - Masalah lainnya

Ketika entri cache menerima cukup banyak umpan balik negatif, entri tersebut akan otomatis dihapus.

## Praktik Terbaik

<AccordionGroup>
  <Accordion title="Gunakan temperature=0 untuk kueri yang dapat di-cache">
    Pengaturan deterministik memaksimalkan tingkat cache hit.
  </Accordion>

  <Accordion title="Standarisasi format prompt">
    Pemformatan yang konsisten meningkatkan pencocokan semantik.
  </Accordion>

  <Accordion title="Gunakan no-cache untuk kueri yang sensitif terhadap waktu">
    Berita terkini dan data real-time harus melewati cache.
  </Accordion>

  <Accordion title="Pantau tingkat cache hit">
    Lihat statistik cache dan jumlah penghematan di dashboard.
  </Accordion>
</AccordionGroup>

## Kapan Tidak Menggunakan Cache

Nonaktifkan cache untuk situasi berikut:

- **Informasi Real-time**: Harga saham, cuaca, berita
- **Konten Personalisasi**: Rekomendasi untuk pengguna tertentu
- **Tugas Kreatif**: Saat variasi diperlukan
- **Data Sensitif**: Informasi rahasia

```python
# Untuk kueri yang sensitif terhadap waktu
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What's the current stock price of AAPL?"}],
    extra_body={"cache_control": {"type": "no_cache"}}
)
```