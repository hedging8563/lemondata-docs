---
title: "Daftar Model"
openapi: "GET /v1beta/models"
description: "Menampilkan daftar model yang tersedia menggunakan format Google Gemini API"
---

Mengembalikan daftar model yang tersedia dalam format Google Gemini API.

## Parameter Query

<ParamField query="pageSize" type="integer">
  Jumlah maksimum model yang akan dikembalikan. Default: `50`, maksimum: `1000`.
</ParamField>

## Autentikasi

Opsional. Mendukung metode autentikasi yang sama dengan endpoint Gemini lainnya:
- Parameter query `?key=YOUR_API_KEY`
- Header `x-goog-api-key: YOUR_API_KEY`
- Header `Authorization: Bearer YOUR_API_KEY`

## Respons

<ResponseField name="models" type="array">
  Array dari objek model.
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models?pageSize=5" \
  -H "x-goog-api-key: sk-your-api-key"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

for model in genai.list_models():
    print(model.name)
```

```javascript JavaScript
const response = await fetch(
  "https://api.lemondata.cc/v1beta/models?pageSize=5",
  { headers: { "x-goog-api-key": "sk-your-api-key" } }
);
const { models } = await response.json();
models.forEach(m => console.log(m.name));
```
</RequestExample>

<ResponseExample>
```json Response
{
  "models": [
    {
      "name": "models/gemini-2.5-pro",
      "version": "1.0",
      "displayName": "gemini-2.5-pro",
      "description": "gemini-2.5-pro model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    },
    {
      "name": "models/gemini-2.5-flash",
      "version": "1.0",
      "displayName": "gemini-2.5-flash",
      "description": "gemini-2.5-flash model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    }
  ]
}
```
</ResponseExample>