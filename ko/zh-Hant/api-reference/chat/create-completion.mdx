---
title: "채팅 완성 생성 (Create Chat Completion)"
openapi: "POST /v1/chat/completions"
description: "대화 메시지에 대한 완성을 생성합니다."
---

## 요청 본문 (Request Body)

<ParamField body="model" type="string" required>
  사용할 모델 ID입니다. 사용 가능한 옵션은 [Models](https://lemondata.cc/zh-TW/models)를 참조하세요.
</ParamField>

<ParamField body="messages" type="array" required>
  대화를 구성하는 메시지 목록입니다.

  각 메시지 객체는 다음을 포함합니다:
  - `role` (string): `system`, `user` 또는 `assistant`
  - `content` (string | array): 메시지 내용
</ParamField>

<ParamField body="temperature" type="number" default="1">
  0에서 2 사이의 샘플링 온도입니다. 값이 높을수록 출력이 더 무작위해집니다.
</ParamField>

<ParamField body="max_tokens" type="integer">
  생성할 최대 token 수입니다.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  true인 경우, 메시지 증분이 SSE 이벤트 형식으로 전송됩니다.
</ParamField>

<ParamField body="stream_options" type="object">
  스트리밍 옵션입니다. `include_usage: true`로 설정하여 스트림 청크에서 token 사용량을 수신하세요.
</ParamField>

<ParamField body="top_p" type="number" default="1">
  핵 샘플링(Nucleus sampling) 파라미터입니다. 이 파라미터 또는 temperature 중 하나만 조정하는 것을 권장합니다.
</ParamField>

<ParamField body="frequency_penalty" type="number" default="0">
  -2.0에서 2.0 사이의 값입니다. 양수 값은 반복되는 token에 페널티를 부여합니다.
</ParamField>

<ParamField body="presence_penalty" type="number" default="0">
  -2.0에서 2.0 사이의 값입니다. 양수 값은 이미 텍스트에 등장한 token에 페널티를 부여합니다.
</ParamField>

<ParamField body="stop" type="string | array">
  최대 4개의 시퀀스로, API는 이 시퀀스에서 token 생성을 중단합니다.
</ParamField>

<ParamField body="tools" type="array">
  모델이 호출할 수 있는 도구 목록(function calling)입니다.
</ParamField>

<ParamField body="tool_choice" type="string | object">
  모델이 도구를 사용하는 방식을 제어합니다. 옵션: `auto`, `none`, `required` 또는 특정 도구 객체.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  병렬 함수 호출 활성화 여부입니다. false로 설정하면 함수를 순차적으로 호출합니다.
</ParamField>

<ParamField body="max_completion_tokens" type="integer">
  완성을 위한 최대 token 수입니다. `max_tokens`의 대안이며, o1/o3와 같은 최신 모델에 권장됩니다.
</ParamField>

<ParamField body="reasoning_effort" type="string">
  o1/o3 모델의 추론 강도입니다. 옵션: `low`, `medium`, `high`.
</ParamField>

<ParamField body="seed" type="integer">
  결정론적 샘플링을 위한 무작위 시드입니다.
</ParamField>

<ParamField body="n" type="integer" default="1">
  생성할 완성 수입니다 (1-128).
</ParamField>

<ParamField body="logprobs" type="boolean">
  로그 확률(log probabilities) 반환 여부입니다.
</ParamField>

<ParamField body="top_logprobs" type="integer">
  반환할 상위 로그 확률 수입니다 (0-20). `logprobs: true` 설정이 필요합니다.
</ParamField>

<ParamField body="top_k" type="integer">
  Top-K 샘플링 파라미터(Anthropic/Gemini 모델에 적용)입니다.
</ParamField>

<ParamField body="response_format" type="object">
  응답 형식 사양입니다. `{"type": "json_object"}`를 사용하여 JSON 모드를 활성화하거나, `{"type": "json_schema", "json_schema": {...}}`를 사용하여 구조화된 출력을 생성하세요.
</ParamField>

<ParamField body="logit_bias" type="object">
  특정 token이 나타날 가능성을 수정합니다. token ID(문자열 형식)를 -100에서 100 사이의 편향 값에 매핑합니다.
</ParamField>

<ParamField body="user" type="string">
  최종 사용자를 나타내는 고유 식별자로, 남용 모니터링에 사용됩니다.
</ParamField>

<ParamField body="cache_control" type="object">
  LemonData 캐시 제어 옵션입니다.

  - `type` (string): 캐시 전략 - `default`, `no_cache`, `no_store`, `response_only`, `semantic_only`
  - `max_age` (integer): 캐시 유지 시간(TTL), 초 단위(최대 86400)
</ParamField>

## 응답 (Response)

<ResponseField name="id" type="string">
  완성의 고유 식별자입니다.
</ResponseField>

<ResponseField name="object" type="string">
  항상 `chat.completion`입니다.
</ResponseField>

<ResponseField name="created" type="integer">
  완성이 생성된 시점의 Unix 타임스탬프입니다.
</ResponseField>

<ResponseField name="model" type="string">
  완성에 사용된 모델입니다.
</ResponseField>

<ResponseField name="choices" type="array">
  완성 선택지 목록입니다.

  각 선택지는 다음을 포함합니다:
  - `index` (integer): 선택지 인덱스
  - `message` (object): 생성된 메시지
  - `finish_reason` (string): 모델이 중단된 이유 (`stop`, `length`, `tool_calls`)
</ResponseField>

<ResponseField name="usage" type="object">
  Token 사용량 통계입니다.

  - `prompt_tokens` (integer): 프롬프트의 token 수
  - `completion_tokens` (integer): 완성의 token 수
  - `total_tokens` (integer): 사용된 총 token 수
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/chat/completions" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    temperature=0.7,
    max_tokens=1000
)

print(response.choices[0].message.content)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'Hello!' }
  ],
  temperature: 0.7,
  max_tokens: 1000
});

console.log(response.choices[0].message.content);
```

```go Go
package main

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("sk-your-api-key")
    config.BaseURL = "https://api.lemondata.cc/v1"
    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "gpt-4o",
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleSystem, Content: "You are a helpful assistant."},
                {Role: openai.ChatMessageRoleUser, Content: "Hello!"},
            },
            Temperature: 0.7,
            MaxTokens:   1000,
        },
    )
    if err != nil {
        panic(err)
    }
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/chat/completions');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'messages' => [
            ['role' => 'system', 'content' => 'You are a helpful assistant.'],
            ['role' => 'user', 'content' => 'Hello!']
        ],
        'temperature' => 0.7,
        'max_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['choices'][0]['message']['content'];
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1706000000,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 9,
    "total_tokens": 29
  }
}
```
</ResponseExample>