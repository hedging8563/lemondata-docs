---
title: "✨ 지능형 캐싱"
description: "문맥 인식 시맨틱 캐싱으로 비용과 지연 시간을 줄이세요"
---

## 개요

LemonData는 API 비용과 응답 지연 시간을 크게 줄일 수 있는 지능형 캐싱 시스템을 제공합니다. 당사의 캐싱은 단순한 요청 매칭을 넘어 프롬프트의 **시맨틱 의미(semantic meaning)**를 이해합니다.

<CardGroup cols={2}>
  <Card title="비용 절감" icon="piggy-bank">
    캐시 히트(Cache hit)는 정상 비용의 일부만 청구됩니다.
  </Card>
  <Card title="빠른 응답" icon="bolt">
    캐시된 응답은 즉시 반환되며, 모델 추론이 필요하지 않습니다.
  </Card>
  <Card title="문맥 인식" icon="brain">
    시맨틱 매칭은 표현이 다르더라도 유사한 요청을 찾아냅니다.
  </Card>
  <Card title="개인정보 제어" icon="shield">
    캐싱 및 공유 대상에 대한 전체 제어 권한을 제공합니다.
  </Card>
</CardGroup>

## 작동 원리

LemonData는 2계층 캐싱 시스템을 사용합니다:

### 계층 1: 응답 캐시 (정확한 일치)

결정론적 요청(`temperature=0`)의 경우, 정확한 응답을 캐싱합니다:

- **일치 항목**: 동일한 모델, 메시지 및 파라미터
- **속도**: 즉시 (마이크로초)
- **최적 용도**: 반복되는 동일한 쿼리

### 계층 2: 시맨틱 캐시 (유사도 일치)

모든 요청에 대해 2단계 매칭 알고리즘을 사용하여 시맨틱 유사성도 확인합니다:

- **1단계 (쿼리 전용)**: 사용자 쿼리에 대해 95% 이상의 유사도
- **2단계 (전체 문맥)**: 대화 문맥을 포함하여 85% 이상의 유사도
- **최적 용도**: FAQ 스타일의 쿼리, 일반적인 질문

```
User A: "What is the capital of France?"
User B: "Tell me the capital city of France"
→ Same cached response (high semantic similarity)
```

## 캐시 헤더

### 요청 헤더

요청별로 캐싱 동작을 제어합니다:

```bash
# Skip cache lookup, always call the model
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-key" \
  -H "Cache-Control: no-cache" \
  -d '{"model": "gpt-4o", "messages": [...]}'
```

| 헤더 | 값 | 효과 |
|--------|-------|--------|
| `Cache-Control: no-cache` | - | 캐시 건너뛰기, 새로운 응답 |
| `Cache-Control: no-store` | - | 이 응답을 캐싱하지 않음 |

### 응답 헤더

모든 응답에는 캐시 상태가 포함됩니다:

```
X-Cache: HIT           # 캐시에서 응답 제공
X-Cache: MISS          # 모델의 새로운 응답
X-Cache-Entry-Id: abc  # 캐시 엔트리 ID (피드백용)
```

## 캐시 상태 확인

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What is 2+2?"}]
)

# Check cache status from response headers
# (Available in raw HTTP response)
print(f"Cache: {response._raw_response.headers.get('X-Cache')}")
```

## 캐시 과금

캐시 히트는 새로운 요청보다 훨씬 저렴합니다:

| 유형 | 비용 |
|------|------|
| 캐시 HIT | **80% 할인** |
| 캐시 MISS | 정가 |

정확한 할인율은 대시보드 사용 로그에 표시됩니다.

## 개인정보 제어

### API 키 수준

대시보드에서 각 API 키에 대한 캐싱 동작을 구성합니다:

| 모드 | 설명 |
|------|-------------|
| **Default** | 캐시 활성화, 유사한 요청과 공유될 수 있음 |
| **No Share** | 캐시 활성화, 하지만 응답은 귀하의 계정에만 비공개로 유지됨 |
| **Disabled** | 캐싱 사용 안 함 |

### 요청 수준

요청별 재정의:

```bash
# Disable caching for this request
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Cache-Control: no-store" \
  -d '...'
```

## 캐시 피드백

잘못된 캐시 응답을 받은 경우 이를 보고할 수 있습니다:

```bash
curl -X POST https://api.lemondata.cc/v1/cache/feedback \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{
    "cache_entry_id": "abc123",
    "feedback_type": "wrong_answer",
    "description": "Response was outdated"
  }'
```

**피드백 유형:**
- `wrong_answer` - 사실과 다름
- `outdated` - 정보가 오래됨
- `irrelevant` - 질문과 일치하지 않음
- `other` - 기타 문제

캐시 엔트리에 부정적인 피드백이 충분히 쌓이면 자동으로 무효화됩니다.

## 권장 사항

<AccordionGroup>
  <Accordion title="캐싱 가능한 쿼리에 temperature=0 사용">
    결정론적 설정은 캐시 히트율을 극대화합니다.
  </Accordion>

  <Accordion title="프롬프트 형식 표준화">
    일관된 포맷팅은 시맨틱 매칭을 개선합니다.
  </Accordion>

  <Accordion title="시간에 민감한 쿼리에 no-cache 사용">
    시사 이슈, 실시간 데이터는 캐시를 건너뛰어야 합니다.
  </Accordion>

  <Accordion title="캐시 히트율 모니터링">
    대시보드에서 캐시 통계 및 절감액을 확인하세요.
  </Accordion>
</AccordionGroup>

## 캐싱을 하지 말아야 할 경우

다음에 대해 캐싱을 비활성화하세요:

- **실시간 정보**: 주가, 날씨, 뉴스
- **개인화된 콘텐츠**: 사용자별 추천
- **창의적 작업**: 다양성이 필요한 경우
- **민감한 데이터**: 기밀 정보

```python
# For time-sensitive queries
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What's the current stock price of AAPL?"}],
    extra_headers={"Cache-Control": "no-cache"}
)
```