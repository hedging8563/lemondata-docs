---
title: "Criar Resposta"
openapi: "POST /v1/responses"
description: "Cria uma resposta usando o formato da API de Responses da OpenAI"
---

A API de Responses é a nova API de conversação com estado da OpenAI. O LemonData suporta este formato para modelos compatíveis.

## Corpo da Requisição

<ParamField body="model" type="string" required>
  ID do modelo a ser utilizado. Veja [Models](https://lemondata.cc/pt/models) para as opções disponíveis.
</ParamField>

<ParamField body="input" type="array" required>
  Uma lista de itens de entrada que compõem a conversa.

  Cada item pode ser:
  - `message`: Uma mensagem de conversa com `role` e `content`
  - `function_call`: Uma solicitação de chamada de função
  - `function_call_output`: Saída de uma chamada de função
</ParamField>

<ParamField body="instructions" type="string">
  Instruções de sistema para o modelo (equivalente à mensagem de sistema).
</ParamField>

<ParamField body="max_output_tokens" type="integer">
  Número máximo de tokens a serem gerados.
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Temperatura de amostragem entre 0 e 2.
</ParamField>

<ParamField body="tools" type="array">
  Uma lista de ferramentas que o modelo pode chamar.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Se verdadeiro, retorna um fluxo (stream) de eventos.
</ParamField>

<ParamField body="previous_response_id" type="string">
  ID de uma resposta anterior para continuar a conversa a partir dela.
</ParamField>

<ParamField body="store" type="boolean" default="true">
  Se deve armazenar a resposta para recuperação posterior.
</ParamField>

<ParamField body="metadata" type="object">
  Metadados para anexar à resposta para fins de rastreamento.
</ParamField>

<ParamField body="text" type="object">
  Opções de configuração de geração de texto.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  Se deve permitir múltiplas chamadas de ferramentas em paralelo.
</ParamField>

<ParamField body="top_p" type="number">
  Parâmetro de amostragem de núcleo (0-1).
</ParamField>

<ParamField body="reasoning" type="object">
  Configuração de raciocínio para modelos o1/o3.

  - `effort` (string): Nível de esforço de raciocínio (`low`, `medium`, `high`)
</ParamField>

## Resposta

<ResponseField name="id" type="string">
  Identificador único para a resposta.
</ResponseField>

<ResponseField name="object" type="string">
  Sempre `response`.
</ResponseField>

<ResponseField name="created_at" type="integer">
  Timestamp Unix de quando a resposta foi criada.
</ResponseField>

<ResponseField name="output" type="array">
  Lista de itens de saída gerados pelo modelo.
</ResponseField>

<ResponseField name="usage" type="object">
  Estatísticas de uso de tokens.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/responses" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"type": "message", "role": "user", "content": "Hello!"}
    ],
    "max_output_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.responses.create(
    model="gpt-4o",
    input=[
        {"type": "message", "role": "user", "content": "Hello!"}
    ],
    max_output_tokens=1000
)

print(response.output)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.responses.create({
  model: 'gpt-4o',
  input: [
    { type: 'message', role: 'user', content: 'Hello!' }
  ],
  max_output_tokens: 1000
});

console.log(response.output);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model": "gpt-4o",
        "input": []map[string]interface{}{
            {"type": "message", "role": "user", "content": "Hello!"},
        },
        "max_output_tokens": 1000,
    }
    body, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/responses", bytes.NewBuffer(body))
    req.Header.Set("Authorization", "Bearer sk-your-api-key")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["output"])
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/responses');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'input' => [
            ['type' => 'message', 'role' => 'user', 'content' => 'Hello!']
        ],
        'max_output_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
print_r($data['output']);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "resp_abc123",
  "object": "response",
  "created_at": 1706000000,
  "model": "gpt-4o",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "Hello! How can I help you today?"}
      ]
    }
  ],
  "usage": {
    "input_tokens": 10,
    "output_tokens": 12,
    "total_tokens": 22
  }
}
```
</ResponseExample>