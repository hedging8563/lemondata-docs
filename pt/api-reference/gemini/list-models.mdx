---
title: "Listar Modelos"
openapi: "GET /v1beta/models"
description: "Lista os modelos disponíveis usando o formato da API Google Gemini"
---

Retorna uma lista de modelos disponíveis no formato da API Google Gemini.

## Parâmetros de Consulta

<ParamField query="pageSize" type="integer">
  Número máximo de modelos a retornar. Padrão: `50`, máximo: `1000`.
</ParamField>

## Autenticação

Opcional. Suporta os mesmos métodos de autenticação que outros endpoints do Gemini:
- Parâmetro de consulta `?key=YOUR_API_KEY`
- Cabeçalho `x-goog-api-key: YOUR_API_KEY`
- Cabeçalho `Authorization: Bearer YOUR_API_KEY`

## Resposta

<ResponseField name="models" type="array">
  Array de objetos de modelo.
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models?pageSize=5" \
  -H "x-goog-api-key: sk-your-api-key"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

for model in genai.list_models():
    print(model.name)
```

```javascript JavaScript
const response = await fetch(
  "https://api.lemondata.cc/v1beta/models?pageSize=5",
  { headers: { "x-goog-api-key": "sk-your-api-key" } }
);
const { models } = await response.json();
models.forEach(m => console.log(m.name));
```
</RequestExample>

<ResponseExample>
```json Response
{
  "models": [
    {
      "name": "models/gemini-2.5-pro",
      "version": "1.0",
      "displayName": "gemini-2.5-pro",
      "description": "gemini-2.5-pro model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    },
    {
      "name": "models/gemini-2.5-flash",
      "version": "1.0",
      "displayName": "gemini-2.5-flash",
      "description": "gemini-2.5-flash model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    }
  ]
}
```
</ResponseExample>