---
title: "Início Rápido"
description: "Comece a usar a LemonData API em 2 minutos"
---

## Passo 1: Obtenha sua API Key

<Steps>
  <Step title="Crie uma conta">
    Cadastre-se em [lemondata.cc](https://lemondata.cc) usando seu e-mail.
  </Step>
  <Step title="Adicione créditos">
    Navegue até o dashboard e adicione créditos à sua conta. Preços no modelo pay-as-you-go sem valor mínimo.
  </Step>
  <Step title="Crie uma API key">
    Vá em **Dashboard → API Keys** e crie uma nova chave. Copie-a com segurança - ela é exibida apenas uma vez.
  </Step>
</Steps>

<Warning>
  Mantenha sua API key segura. Nunca a exponha em código do lado do cliente ou em repositórios públicos.
</Warning>

## Passo 2: Instale o SDK

<CodeGroup>

```bash Python
pip install openai
```

```bash JavaScript
npm install openai
```

```bash Go
go get github.com/sashabaranov/go-openai
```

```bash PHP
composer require openai-php/client
```

</CodeGroup>

## Passo 3: Faça sua Primeira Requisição

<CodeGroup>

```bash cURL
curl https://api.lemondata.cc/v1/chat/completions \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is the capital of France?"}
    ]
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ]
)

print(response.choices[0].message.content)
# Output: The capital of France is Paris.
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'What is the capital of France?' }
  ]
});

console.log(response.choices[0].message.content);
// Output: The capital of France is Paris.
```

```go Go
package main

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("sk-your-api-key")
    config.BaseURL = "https://api.lemondata.cc/v1"

    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "gpt-4o",
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleSystem, Content: "You are a helpful assistant."},
                {Role: openai.ChatMessageRoleUser, Content: "What is the capital of France?"},
            },
        },
    )
    if err != nil {
        panic(err)
    }
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/chat/completions');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'messages' => [
            ['role' => 'system', 'content' => 'You are a helpful assistant.'],
            ['role' => 'user', 'content' => 'What is the capital of France?']
        ]
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['choices'][0]['message']['content'];
// Output: The capital of France is Paris.
```

</CodeGroup>

## Experimente Diferentes Modelos

A LemonData suporta mais de 300 modelos. Basta alterar o parâmetro `model`:

```python
# OpenAI GPT-4o
response = client.chat.completions.create(model="gpt-4o", messages=messages)

# Anthropic Claude Sonnet 4.5
response = client.chat.completions.create(model="claude-sonnet-4-5", messages=messages)

# Google Gemini 2.5 Flash
response = client.chat.completions.create(model="gemini-2.5-flash", messages=messages)

# DeepSeek R1
response = client.chat.completions.create(model="deepseek-r1", messages=messages)
```

## Habilite o Streaming

Para respostas em tempo real, habilite o streaming:

```python
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

## Próximos Passos

<CardGroup cols={2}>
  <Card title="Autenticação" icon="key" href="/authentication">
    Saiba mais sobre o gerenciamento e a segurança de API keys.
  </Card>
  <Card title="Modelos" icon="robot" href="https://lemondata.cc/pt/models">
    Explore todos os modelos disponíveis e suas capacidades.
  </Card>
  <Card title="Streaming" icon="bolt" href="/guides/streaming">
    Implemente respostas em streaming em tempo real.
  </Card>
  <Card title="Tratamento de Erros" icon="triangle-exclamation" href="/guides/error-handling">
    Trate erros de forma adequada em sua aplicação.
  </Card>
</CardGroup>