---
title: "创建对话补全"
openapi: "POST /v1/chat/completions"
description: "为对话消息创建补全"
---

## 请求体

<ParamField body="model" type="string" required>
  要使用的模型 ID。有关可用选项，请参阅 [Models](https://lemondata.cc/zh/models)。
</ParamField>

<ParamField body="messages" type="array" required>
  构成对话的消息列表。

  每个消息对象包含：
  - `role` (string): `system`、`user` 或 `assistant`
  - `content` (string | array): 消息内容
</ParamField>

<ParamField body="temperature" type="number" default="1">
  介于 0 到 2 之间的采样温度。较高的值会使输出更具随机性。
</ParamField>

<ParamField body="max_tokens" type="integer">
  生成的最大 token 数量。
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  如果为 true，部分消息增量将作为 SSE 事件发送。
</ParamField>

<ParamField body="stream_options" type="object">
  流式传输选项。设置 `include_usage: true` 以在流数据块中接收 token 使用情况。
</ParamField>

<ParamField body="top_p" type="number" default="1">
  核采样参数。我们建议修改此参数或 `temperature`，但不要同时修改两者。
</ParamField>

<ParamField body="frequency_penalty" type="number" default="0">
  介于 -2.0 到 2.0 之间的数值。正值会惩罚重复的 token。
</ParamField>

<ParamField body="presence_penalty" type="number" default="0">
  介于 -2.0 到 2.0 之间的数值。正值会惩罚文本中已出现的 token。
</ParamField>

<ParamField body="stop" type="string | array">
  API 将停止生成 token 的最多 4 个序列。
</ParamField>

<ParamField body="tools" type="array">
  模型可能调用的工具列表（function calling）。
</ParamField>

<ParamField body="tool_choice" type="string | object">
  控制模型如何使用工具。选项：`auto`、`none`、`required` 或特定的工具对象。
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  是否启用并行函数调用。设置为 false 以按顺序调用函数。
</ParamField>

<ParamField body="max_completion_tokens" type="integer">
  补全的最大 token 数量。`max_tokens` 的替代方案，更适用于 `o1`/`o3` 等较新模型值。
</ParamField>

<ParamField body="reasoning_effort" type="string">
  `o1`/`o3` 模型的推理力度。选项：`low`、`medium`、`high`。
</ParamField>

<ParamField body="seed" type="integer">
  用于确定性采样的随机种子。
</ParamField>

<ParamField body="n" type="integer" default="1">
  生成的补全数量 (1-128)。
</ParamField>

<ParamField body="logprobs" type="boolean">
  是否返回对数概率。
</ParamField>

<ParamField body="top_logprobs" type="integer">
  返回的前几个对数概率的数量 (0-20)。需要设置 `logprobs: true`。
</ParamField>

<ParamField body="top_k" type="integer">
  Top-K 采样参数（适用于 Anthropic/Gemini 模型）。
</ParamField>

<ParamField body="response_format" type="object">
  响应格式规范。使用 `{"type": "json_object"}` 开启 JSON 模式，或使用 `{"type": "json_schema", "json_schema": {...}}` 获取结构化输出。
</ParamField>

<ParamField body="logit_bias" type="object">
  修改指定 token 出现的可能性。将 token ID（作为字符串）映射到 -100 到 100 之间的偏置值。
</ParamField>

<ParamField body="user" type="string">
  代表终端用户的唯一标识符，用于滥用监控。
</ParamField>

<ParamField body="cache_control" type="object">
  LemonData 缓存控制选项。

  - `type` (string): 缓存策略 - `default`、`no_cache`、`no_store`、`response_only`、`semantic_only`
  - `max_age` (integer): 缓存 TTL（以秒为单位，最大 86400）
</ParamField>

## 响应

<ResponseField name="id" type="string">
  补全的唯一标识符。
</ResponseField>

<ResponseField name="object" type="string">
  始终为 `chat.completion`。
</ResponseField>

<ResponseField name="created" type="integer">
  补全创建时的 Unix 时间戳。
</ResponseField>

<ResponseField name="model" type="string">
  用于补全的模型。
</ResponseField>

<ResponseField name="choices" type="array">
  补全选项列表。

  每个选项包含：
  - `index` (integer): 选项的索引
  - `message` (object): 生成的消息
  - `finish_reason` (string): 模型停止的原因 (`stop`、`length`、`tool_calls`)
</ResponseField>

<ResponseField name="usage" type="object">
  Token 使用情况统计。

  - `prompt_tokens` (integer): 提示词中的 token 数量
  - `completion_tokens` (integer): 补全中的 token 数量
  - `total_tokens` (integer): 使用的总 token 数量
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/chat/completions" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    temperature=0.7,
    max_tokens=1000
)

print(response.choices[0].message.content)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'Hello!' }
  ],
  temperature: 0.7,
  max_tokens: 1000
});

console.log(response.choices[0].message.content);
```

```go Go
package main

import (
    "context"
    "fmt"
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("sk-your-api-key")
    config.BaseURL = "https://api.lemondata.cc/v1"
    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "gpt-4o",
            Messages: []openai.ChatCompletionMessage{
                {Role: openai.ChatMessageRoleSystem, Content: "You are a helpful assistant."},
                {Role: openai.ChatMessageRoleUser, Content: "Hello!"},
            },
            Temperature: 0.7,
            MaxTokens:   1000,
        },
    )
    if err != nil {
        panic(err)
    }
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/chat/completions');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'messages' => [
            ['role' => 'system', 'content' => 'You are a helpful assistant.'],
            ['role' => 'user', 'content' => 'Hello!']
        ],
        'temperature' => 0.7,
        'max_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['choices'][0]['message']['content'];
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1706000000,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 9,
    "total_tokens": 29
  }
}
```
</ResponseExample>