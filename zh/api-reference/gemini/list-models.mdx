---
title: "列出模型"
openapi: "GET /v1beta/models"
description: "使用 Google Gemini API 格式列出可用模型"
---

返回以 Google Gemini API 格式表示的可用模型列表。

## 查询参数

<ParamField query="pageSize" type="integer">
  要返回的模型最大数量。默认值：`50`，最大值：`1000`。
</ParamField>

## 身份验证

可选。支持与其他 Gemini 端点相同的身份验证方法：
- `?key=YOUR_API_KEY` 查询参数
- `x-goog-api-key: YOUR_API_KEY` 请求头
- `Authorization: Bearer YOUR_API_KEY` 请求头

## 响应

<ResponseField name="models" type="array">
  模型对象数组。
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models?pageSize=5" \
  -H "x-goog-api-key: sk-your-api-key"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

for model in genai.list_models():
    print(model.name)
```

```javascript JavaScript
const response = await fetch(
  "https://api.lemondata.cc/v1beta/models?pageSize=5",
  { headers: { "x-goog-api-key": "sk-your-api-key" } }
);
const { models } = await response.json();
models.forEach(m => console.log(m.name));
```
</RequestExample>

<ResponseExample>
```json Response
{
  "models": [
    {
      "name": "models/gemini-2.5-pro",
      "version": "1.0",
      "displayName": "gemini-2.5-pro",
      "description": "gemini-2.5-pro model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    },
    {
      "name": "models/gemini-2.5-flash",
      "version": "1.0",
      "displayName": "gemini-2.5-flash",
      "description": "gemini-2.5-flash model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    }
  ]
}
```
</ResponseExample>