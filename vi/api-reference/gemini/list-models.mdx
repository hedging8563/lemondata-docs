---
title: "Danh sách Model"
openapi: "GET /v1beta/models"
description: "Liệt kê các model hiện có bằng định dạng Google Gemini API"
---

Trả về danh sách các model hiện có theo định dạng Google Gemini API.

## Tham số Query

<ParamField query="pageSize" type="integer">
  Số lượng model tối đa được trả về. Mặc định: `50`, tối đa: `1000`.
</ParamField>

## Xác thực

Tùy chọn. Hỗ trợ các phương thức xác thực tương tự như các endpoint Gemini khác:
- Tham số query `?key=YOUR_API_KEY`
- Header `x-goog-api-key: YOUR_API_KEY`
- Header `Authorization: Bearer YOUR_API_KEY`

## Phản hồi

<ResponseField name="models" type="array">
  Mảng các đối tượng model.
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models?pageSize=5" \
  -H "x-goog-api-key: sk-your-api-key"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

for model in genai.list_models():
    print(model.name)
```

```javascript JavaScript
const response = await fetch(
  "https://api.lemondata.cc/v1beta/models?pageSize=5",
  { headers: { "x-goog-api-key": "sk-your-api-key" } }
);
const { models } = await response.json();
models.forEach(m => console.log(m.name));
```
</RequestExample>

<ResponseExample>
```json Response
{
  "models": [
    {
      "name": "models/gemini-2.5-pro",
      "version": "1.0",
      "displayName": "gemini-2.5-pro",
      "description": "gemini-2.5-pro model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    },
    {
      "name": "models/gemini-2.5-flash",
      "version": "1.0",
      "displayName": "gemini-2.5-flash",
      "description": "gemini-2.5-flash model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    }
  ]
}
```
</ResponseExample>