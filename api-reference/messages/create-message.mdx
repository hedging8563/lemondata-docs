---
title: "Create Message"
api: "POST /v1/messages"
description: "Creates a message using the Anthropic Messages API format"
---

## Overview

This endpoint provides native Anthropic Messages API compatibility. Use this for Claude models with features like extended thinking.

<Note>
Base URL for Anthropic SDK: `https://api.lemondata.cc` (no `/v1` suffix)
</Note>

## Request Headers

<ParamField header="x-api-key" type="string" required>
  Your LemonData API key. Alternative to Bearer token.
</ParamField>

<ParamField header="anthropic-version" type="string" required>
  Anthropic API version. Use `2023-06-01`.
</ParamField>

## Request Body

<ParamField body="model" type="string" required>
  Claude model ID (e.g., `claude-sonnet-4-5`).
</ParamField>

<ParamField body="messages" type="array" required>
  Array of message objects with `role` and `content`.
</ParamField>

<ParamField body="max_tokens" type="integer" required>
  Maximum tokens to generate.
</ParamField>

<ParamField body="system" type="string">
  System prompt (separate from messages array).
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Sampling temperature (0-1).
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Enable streaming responses.
</ParamField>

<ParamField body="thinking" type="object">
  Extended thinking configuration (Claude Opus 4.5).

  - `type` (string): `"enabled"` to enable
  - `budget_tokens` (integer): Token budget for thinking
</ParamField>

<ParamField body="tools" type="array">
  Available tools for the model.
</ParamField>

<ParamField body="tool_choice" type="object">
  How the model should use tools. Options: `auto`, `any`, `tool` (specific tool).
</ParamField>

<ParamField body="top_p" type="number">
  Nucleus sampling parameter. Use either temperature or top_p, not both.
</ParamField>

<ParamField body="top_k" type="integer">
  Only sample from the top K options for each token.
</ParamField>

<ParamField body="stop_sequences" type="array">
  Custom stop sequences that will cause the model to stop generating.
</ParamField>

<ParamField body="metadata" type="object">
  Metadata to attach to the request for tracking purposes.
</ParamField>

## Response

<ResponseField name="id" type="string">
  Unique message identifier.
</ResponseField>

<ResponseField name="type" type="string">
  Always `message`.
</ResponseField>

<ResponseField name="role" type="string">
  Always `assistant`.
</ResponseField>

<ResponseField name="content" type="array">
  Array of content blocks (text, thinking, tool_use).
</ResponseField>

<ResponseField name="model" type="string">
  Model used.
</ResponseField>

<ResponseField name="stop_reason" type="string">
  Why generation stopped (`end_turn`, `max_tokens`, `tool_use`).
</ResponseField>

<ResponseField name="usage" type="object">
  Token usage with `input_tokens` and `output_tokens`.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/messages" \
  -H "x-api-key: sk-your-api-key" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "system": "You are a helpful assistant.",
    "messages": [
      {"role": "user", "content": "Hello, Claude!"}
    ]
  }'
```

```python Python
from anthropic import Anthropic

client = Anthropic(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc"
)

message = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    system="You are a helpful assistant.",
    messages=[
        {"role": "user", "content": "Hello, Claude!"}
    ]
)

print(message.content[0].text)
```

```javascript JavaScript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc'
});

const message = await client.messages.create({
  model: 'claude-sonnet-4-5',
  max_tokens: 1024,
  system: 'You are a helpful assistant.',
  messages: [
    { role: 'user', content: 'Hello, Claude!' }
  ]
});

console.log(message.content[0].text);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "msg_abc123",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you today?"
    }
  ],
  "model": "claude-sonnet-4-5",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 15,
    "output_tokens": 10
  }
}
```
</ResponseExample>

## Extended Thinking Example

```python
message = client.messages.create(
    model="claude-opus-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    messages=[{"role": "user", "content": "Solve this math problem..."}]
)

for block in message.content:
    if block.type == "thinking":
        print(f"Thinking: {block.thinking}")
    elif block.type == "text":
        print(f"Response: {block.text}")
```

