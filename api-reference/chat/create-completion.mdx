---
title: "Create Chat Completion"
api: "POST /v1/chat/completions"
description: "Creates a completion for the chat message"
---

## Request Body

<ParamField body="model" type="string" required>
  ID of the model to use. See [Models](https://lemondata.cc/en/models) for available options.
</ParamField>

<ParamField body="messages" type="array" required>
  A list of messages comprising the conversation.

  Each message object contains:
  - `role` (string): `system`, `user`, or `assistant`
  - `content` (string | array): The message content
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Sampling temperature between 0 and 2. Higher values make output more random.
</ParamField>

<ParamField body="max_tokens" type="integer">
  Maximum number of tokens to generate.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  If true, partial message deltas will be sent as SSE events.
</ParamField>

<ParamField body="top_p" type="number" default="1">
  Nucleus sampling parameter. We recommend altering this or temperature, not both.
</ParamField>

<ParamField body="frequency_penalty" type="number" default="0">
  Number between -2.0 and 2.0. Positive values penalize repeated tokens.
</ParamField>

<ParamField body="presence_penalty" type="number" default="0">
  Number between -2.0 and 2.0. Positive values penalize tokens already in the text.
</ParamField>

<ParamField body="stop" type="string | array">
  Up to 4 sequences where the API will stop generating tokens.
</ParamField>

<ParamField body="tools" type="array">
  A list of tools the model may call (function calling).
</ParamField>

## Response

<ResponseField name="id" type="string">
  Unique identifier for the completion.
</ResponseField>

<ResponseField name="object" type="string">
  Always `chat.completion`.
</ResponseField>

<ResponseField name="created" type="integer">
  Unix timestamp of when the completion was created.
</ResponseField>

<ResponseField name="model" type="string">
  The model used for completion.
</ResponseField>

<ResponseField name="choices" type="array">
  List of completion choices.

  Each choice contains:
  - `index` (integer): Index of the choice
  - `message` (object): The generated message
  - `finish_reason` (string): Why the model stopped (`stop`, `length`, `tool_calls`)
</ResponseField>

<ResponseField name="usage" type="object">
  Token usage statistics.

  - `prompt_tokens` (integer): Tokens in the prompt
  - `completion_tokens` (integer): Tokens in the completion
  - `total_tokens` (integer): Total tokens used
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/chat/completions" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    temperature=0.7,
    max_tokens=1000
)

print(response.choices[0].message.content)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'Hello!' }
  ],
  temperature: 0.7,
  max_tokens: 1000
});

console.log(response.choices[0].message.content);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1706000000,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 9,
    "total_tokens": 29
  }
}
```
</ResponseExample>

