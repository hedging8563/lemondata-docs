---
title: "Create Translation"
api: "POST /v1/audio/translations"
description: "Translates audio into English text"
---

## Overview

Translates audio in any supported language into English text. Unlike transcription, this endpoint always outputs English text regardless of the input language.

## Request Body

<ParamField body="file" type="file" required>
  The audio file to translate. Supported formats: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav`, `webm`. Maximum file size is 25 MB.
</ParamField>

<ParamField body="model" type="string" default="whisper-1">
  The model to use. Currently only `whisper-1` is supported.
</ParamField>

<ParamField body="prompt" type="string">
  An optional text to guide the model's style or continue a previous segment. Should be in English.
</ParamField>

<ParamField body="response_format" type="string" default="json">
  The format of the output. Options: `json`, `text`, `srt`, `verbose_json`, `vtt`.
</ParamField>

<ParamField body="temperature" type="number">
  The sampling temperature, between 0 and 1. Higher values like 0.8 produce more random output, while lower values like 0.2 make output more focused and deterministic.
</ParamField>

## Response

<ResponseField name="text" type="string">
  The translated text in English.
</ResponseField>

For `verbose_json` format, the response also includes:

<ResponseField name="language" type="string">
  The detected language of the input audio.
</ResponseField>

<ResponseField name="duration" type="number">
  The duration of the input audio in seconds.
</ResponseField>

<ResponseField name="segments" type="array">
  Segments of the translated text with timestamps.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/audio/translations" \
  -H "Authorization: Bearer sk-your-api-key" \
  -F "file=@german_audio.mp3" \
  -F "model=whisper-1"
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

with open("german_audio.mp3", "rb") as audio_file:
    response = client.audio.translations.create(
        model="whisper-1",
        file=audio_file
    )

print(response.text)
```

```javascript JavaScript
import OpenAI from 'openai';
import fs from 'fs';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.audio.translations.create({
  model: 'whisper-1',
  file: fs.createReadStream('german_audio.mp3')
});

console.log(response.text);
```
</RequestExample>

<ResponseExample>
```json json
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you from?"
}
```

```json verbose_json
{
  "task": "translate",
  "language": "german",
  "duration": 8.470000267028809,
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you from?",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 4.0,
      "text": " Hello, my name is Wolfgang and I come from Germany.",
      "tokens": [50364, 2425, 11, 452, 1315, 307, 25329, 293, 286, 808, 490, 5765, 13, 50564],
      "temperature": 0.0,
      "avg_logprob": -0.45,
      "compression_ratio": 1.0,
      "no_speech_prob": 0.0
    }
  ]
}
```
</ResponseExample>

## Translation vs Transcription

| Feature | Translation | Transcription |
|---------|-------------|---------------|
| Output language | Always English | Same as input |
| Use case | Convert foreign audio to English | Preserve original language |
| Language parameter | Not applicable | Optional hint |

<Note>
  The translation endpoint automatically detects the source language and translates to English. The `language` parameter from transcription is ignored.
</Note>

