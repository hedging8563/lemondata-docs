---
title: "List Models"
openapi: "GET /v1beta/models"
description: "List available models using Google Gemini API format"
---

Returns a list of available models in Google Gemini API format.

## Query Parameters

<ParamField query="pageSize" type="integer">
  Maximum number of models to return. Default: `50`, maximum: `1000`.
</ParamField>

## Authentication

Optional. Supports the same authentication methods as other Gemini endpoints:
- `?key=YOUR_API_KEY` query parameter
- `x-goog-api-key: YOUR_API_KEY` header
- `Authorization: Bearer YOUR_API_KEY` header

## Response

<ResponseField name="models" type="array">
  Array of model objects.
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models?pageSize=5" \
  -H "x-goog-api-key: sk-your-api-key"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

for model in genai.list_models():
    print(model.name)
```

```javascript JavaScript
const response = await fetch(
  "https://api.lemondata.cc/v1beta/models?pageSize=5",
  { headers: { "x-goog-api-key": "sk-your-api-key" } }
);
const { models } = await response.json();
models.forEach(m => console.log(m.name));
```
</RequestExample>

<ResponseExample>
```json Response
{
  "models": [
    {
      "name": "models/gemini-2.5-pro",
      "version": "1.0",
      "displayName": "gemini-2.5-pro",
      "description": "gemini-2.5-pro model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    },
    {
      "name": "models/gemini-2.5-flash",
      "version": "1.0",
      "displayName": "gemini-2.5-flash",
      "description": "gemini-2.5-flash model available via LemonData",
      "inputTokenLimit": 1048576,
      "outputTokenLimit": 65536,
      "supportedGenerationMethods": ["generateContent", "countTokens"],
      "temperature": 1.0,
      "topP": 0.95,
      "topK": 40,
      "maxTemperature": 2.0
    }
  ]
}
```
</ResponseExample>
