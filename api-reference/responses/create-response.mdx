---
title: "Create Response"
openapi: "POST /v1/responses"
description: "Creates a response using the OpenAI Responses API format"
---

## Authorization

<ParamField header="Authorization" type="string" required>
  Bearer token for API authentication. Format: `Bearer sk-your-api-key`
</ParamField>

The Responses API is OpenAI's newer stateful conversation API. LemonData supports this format for compatible models.

## Request Body

<ParamField body="model" type="string" required>
  ID of the model to use. See [Models](https://lemondata.cc/en/models) for available options.
</ParamField>

<ParamField body="input" type="array" required>
  A list of input items comprising the conversation.

  Each item can be:
  - `message`: A conversation message with role and content
  - `function_call`: A function call request
  - `function_call_output`: Output from a function call
</ParamField>

<ParamField body="instructions" type="string">
  System instructions for the model (equivalent to system message).
</ParamField>

<ParamField body="max_output_tokens" type="integer">
  Maximum number of tokens to generate.
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Sampling temperature between 0 and 2.
</ParamField>

<ParamField body="tools" type="array">
  A list of tools the model may call.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  If true, returns a stream of events.
</ParamField>

<ParamField body="previous_response_id" type="string">
  ID of a previous response to continue the conversation from.
</ParamField>

<ParamField body="store" type="boolean" default="true">
  Whether to store the response for later retrieval.
</ParamField>

<ParamField body="metadata" type="object">
  Metadata to attach to the response for tracking purposes.
</ParamField>

<ParamField body="text" type="object">
  Text generation configuration options.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  Whether to allow multiple tool calls in parallel.
</ParamField>

<ParamField body="top_p" type="number">
  Nucleus sampling parameter (0-1).
</ParamField>

<ParamField body="reasoning" type="object">
  Reasoning configuration for o1/o3 models.

  - `effort` (string): Reasoning effort level (`low`, `medium`, `high`)
</ParamField>

## Response

<ResponseField name="id" type="string">
  Unique identifier for the response.
</ResponseField>

<ResponseField name="object" type="string">
  Always `response`.
</ResponseField>

<ResponseField name="created_at" type="integer">
  Unix timestamp of when the response was created.
</ResponseField>

<ResponseField name="output" type="array">
  List of output items generated by the model.
</ResponseField>

<ResponseField name="usage" type="object">
  Token usage statistics.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/responses" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"type": "message", "role": "user", "content": "Hello!"}
    ],
    "max_output_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.responses.create(
    model="gpt-4o",
    input=[
        {"type": "message", "role": "user", "content": "Hello!"}
    ],
    max_output_tokens=1000
)

print(response.output)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.responses.create({
  model: 'gpt-4o',
  input: [
    { type: 'message', role: 'user', content: 'Hello!' }
  ],
  max_output_tokens: 1000
});

console.log(response.output);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model": "gpt-4o",
        "input": []map[string]interface{}{
            {"type": "message", "role": "user", "content": "Hello!"},
        },
        "max_output_tokens": 1000,
    }
    body, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/responses", bytes.NewBuffer(body))
    req.Header.Set("Authorization", "Bearer sk-your-api-key")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["output"])
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/responses');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'input' => [
            ['type' => 'message', 'role' => 'user', 'content' => 'Hello!']
        ],
        'max_output_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
print_r($data['output']);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "resp_abc123",
  "object": "response",
  "created_at": 1706000000,
  "model": "gpt-4o",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "Hello! How can I help you today?"}
      ]
    }
  ],
  "usage": {
    "input_tokens": 10,
    "output_tokens": 12,
    "total_tokens": 22
  }
}
```
</ResponseExample>
