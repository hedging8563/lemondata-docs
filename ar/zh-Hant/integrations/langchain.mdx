---
title: "LangChain"
description: "دمج LemonData مع LangChain"
---

## نظرة عامة

LangChain هو إطار عمل شهير لبناء تطبيقات LLM. يعمل LemonData بسلاسة مع تكامل OpenAI الخاص بـ LangChain.

## التثبيت

```bash
pip install langchain langchain-openai
```

## التكوين الأساسي

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o",
    api_key="sk-your-lemondata-key",
    base_url="https://api.lemondata.cc/v1"
)

response = llm.invoke("Hello, how are you?")
print(response.content)
```

## استخدام نماذج مختلفة

الوصول إلى أي نموذج من نماذج LemonData:

```python
# OpenAI GPT-4o
gpt4 = ChatOpenAI(
    model="gpt-4o",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

# Anthropic Claude
claude = ChatOpenAI(
    model="claude-sonnet-4-5",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

# Google Gemini
gemini = ChatOpenAI(
    model="gemini-2.5-flash",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

# DeepSeek
deepseek = ChatOpenAI(
    model="deepseek-r1",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)
```

## المحادثة باستخدام سجل الرسائل

```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="What is the capital of France?")
]

response = llm.invoke(messages)
print(response.content)
```

## البث (Streaming)

```python
for chunk in llm.stream("Write a poem about coding"):
    print(chunk.content, end="", flush=True)
```

## الاستخدام غير المتزامن

```python
import asyncio

async def main():
    response = await llm.ainvoke("Hello!")
    print(response.content)

asyncio.run(main())
```

## السلاسل (Chains)

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that translates {input_language} to {output_language}."),
    ("human", "{text}")
])

chain = prompt | llm | StrOutputParser()

result = chain.invoke({
    "input_language": "English",
    "output_language": "French",
    "text": "Hello, how are you?"
})
print(result)
```

## RAG (توليد الاسترجاع المعزز)

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# Embeddings
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1"
)

# Create vector store
texts = ["LemonData supports 300+ AI models", "API is OpenAI compatible"]
vectorstore = FAISS.from_texts(texts, embeddings)
retriever = vectorstore.as_retriever()

# RAG chain
template = """Answer based on context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)

rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
)

response = rag_chain.invoke("How many models does LemonData support?")
print(response.content)
```

## الوكلاء (Agents)

<Note>
  واجهة برمجة تطبيقات agent في LangChain تتطور باستمرار. بالنسبة للمشاريع الجديدة، يرجى التفكير في استخدام [LangGraph](https://python.langchain.com/docs/langgraph) للحصول على بنية وكلاء أكثر مرونة.
</Note>

```python
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool

@tool
def search(query: str) -> str:
    """Search for information."""
    return f"Search results for: {query}"

tools = [search]

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant with access to tools."),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}")
])

agent = create_openai_tools_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools)

result = executor.invoke({"input": "Search for LemonData pricing"})
print(result["output"])
```

## متغيرات البيئة

لجعل الكود أكثر إيجازاً، يرجى استخدام متغيرات البيئة:

```bash
export OPENAI_API_KEY="sk-your-lemondata-key"
export OPENAI_API_BASE="https://api.lemondata.cc/v1"
```

```python
from langchain_openai import ChatOpenAI

# Will automatically use environment variables
llm = ChatOpenAI(model="gpt-4o")
```

## الاستدعاءات (Callbacks) والتتبع

```python
from langchain_core.callbacks import StdOutCallbackHandler

llm = ChatOpenAI(
    model="gpt-4o",
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1",
    callbacks=[StdOutCallbackHandler()]
)
```

## أفضل الممارسات

<AccordionGroup>
  <Accordion title="اختيار النموذج المناسب بناءً على التكلفة">
    استخدم نماذج أرخص (GPT-4o-mini) في السلاسل للمهام البسيطة.
  </Accordion>

  <Accordion title="تنفيذ آليات إعادة المحاولة">
    يوفر LangChain منطق إعادة محاولة مدمج للأخطاء المؤقتة.
  </Accordion>

  <Accordion title="مراقبة استخدام الـ token">
    استخدم الاستدعاءات (callbacks) لتتبع استهلاك الـ token.
  </Accordion>
</AccordionGroup>