---
title: "حدود المعدل"
description: "فهم ومعالجة حدود المعدل"
---

## نظرة عامة

تطبق LemonData حدود المعدل (Rate Limits) لضمان الاستخدام العادل واستقرار المنصة. تختلف القيود بناءً على مستوى الحساب.

## مستويات حدود المعدل

| المستوى | الطلبات/الدقيقة | الوصف |
|------|-------------|-------------|
| **User** | 1,000 | المستوى الافتراضي لجميع الحسابات |
| **Partner** | 3,000 | مخصص لشركاء التكامل |
| **VIP** | 10,000 | للمستخدمين ذوي الاستخدام العالي |

<Note>
  قد تخضع حدود المعدل للتغيير. يرجى التواصل مع support@lemondata.cc للحصول على حدود مخصصة.
</Note>

## رؤوس حدود المعدل

يحتوي كل استجابة API على معلومات حدود المعدل:

```
X-RateLimit-Limit: 60          # حدك في الدقيقة
X-RateLimit-Remaining: 55      # الطلبات المتبقية
X-RateLimit-Reset: 1234567890  # طابع Unix الزمني عند إعادة تعيين الحد
```

## تجاوز حد المعدل

عندما تتجاوز الحد، ستتلقى استجابة `429`:

```json
{
  "error": {
    "message": "Rate limit exceeded. Please slow down.",
    "type": "rate_limit_exceeded"
  }
}
```

مع رأس إضافي:
```
Retry-After: 60  # الثواني التي يجب انتظارها قبل إعادة المحاولة
```

## معالجة حدود المعدل

### التراجع الأسي (Exponential Backoff)

قم بتنفيذ التراجع الأسي لإعادة المحاولة تلقائياً:

```python
import time
from openai import OpenAI, RateLimitError

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

def make_request_with_backoff(messages, max_retries=5):
    for attempt in range(max_retries):
        try:
            return client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
        except RateLimitError as e:
            if attempt == max_retries - 1:
                raise

            wait_time = 2 ** attempt  # 1، 2، 4، 8، 16 ثانية
            print(f"Rate limited. Waiting {wait_time}s...")
            time.sleep(wait_time)
```

### طابور الطلبات

بالنسبة للتطبيقات ذات الاستخدام العالي، قم بتنفيذ طابور الطلبات:

```python
import asyncio
from collections import deque

class RateLimitedClient:
    def __init__(self, requests_per_minute=60):
        self.rpm = requests_per_minute
        self.interval = 60 / requests_per_minute
        self.last_request = 0

    async def request(self, messages):
        # الانتظار إذا لزم الأمر لاحترام حد المعدل
        now = asyncio.get_event_loop().time()
        wait_time = max(0, self.last_request + self.interval - now)
        if wait_time > 0:
            await asyncio.sleep(wait_time)

        self.last_request = asyncio.get_event_loop().time()
        return await self.client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
```

### المعالجة المجمعة

بالنسبة للعمليات الكبيرة، استخدم المعالجة المجمعة مع تأخير:

```python
def process_batch(items, batch_size=50, delay=1):
    results = []
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        for item in batch:
            result = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": item}]
            )
            results.append(result)
        time.sleep(delay)  # توقف مؤقت بين الدفعات
    return results
```

## أفضل الممارسات

<AccordionGroup>
  <Accordion title="مراقبة استخدامك">
    تتبع رؤوس حدود المعدل للبقاء ضمن القيود بشكل استباقي.
  </Accordion>

  <Accordion title="تنفيذ التخزين المؤقت">
    قم بتخزين استجابات الطلبات المتطابقة مؤقتاً لتقليل استدعاءات API.
  </Accordion>

  <Accordion title="استخدام النماذج المناسبة">
    توفر النماذج الأسرع (مثل gpt-4o-mini) إنتاجية أعلى.
  </Accordion>

  <Accordion title="اتصل بنا للحصول على حدود أعلى">
    إذا كنت بحاجة إلى حدود أعلى، يرجى التواصل مع support@lemondata.cc.
  </Accordion>
</AccordionGroup>

## ترقية مستواك

لطلب ترقية المستوى:

1. قم بتسجيل الدخول إلى [لوحة التحكم](https://lemondata.cc/dashboard)
2. انتقل إلى **Settings ← Account**
3. تواصل مع فريق الدعم واشرح حالة الاستخدام الخاصة بك

أو أرسل بريداً إلكترونياً إلى support@lemondata.cc مع توفير:
- بريدك الإلكتروني المسجل في الحساب
- حجم الطلبات المتوقع
- وصف لحالة الاستخدام