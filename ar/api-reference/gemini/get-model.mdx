---
title: "الحصول على النموذج"
openapi: "GET /v1beta/models/{model}"
description: "الحصول على البيانات الوصفية للنموذج باستخدام تنسيق Google Gemini API"
---

إرجاع البيانات الوصفية لنموذج محدد بتنسيق Google Gemini API.

## معلمات المسار

<ParamField path="model" type="string" required>
  اسم النموذج (على سبيل المثال، `gemini-2.5-pro` ،`gemini-2.5-flash`). تُقبل الأسماء المستعارة (Aliases) أيضاً.
</ParamField>

## المصادقة

اختياري. يدعم نفس طرق المصادقة مثل نقاط نهاية Gemini الأخرى:
- معلمة الاستعلام `?key=YOUR_API_KEY`
- ترويسة `x-goog-api-key: YOUR_API_KEY`
- ترويسة `Authorization: Bearer YOUR_API_KEY`

## الاستجابة

<ResponseField name="name" type="string">
  اسم مورد النموذج بتنسيق `models/{model}`.
</ResponseField>

<ResponseField name="displayName" type="string">
  اسم النموذج المقروء بشرياً.
</ResponseField>

<ResponseField name="inputTokenLimit" type="integer">
  الحد الأقصى لرموز الإدخال `input tokens` (نافذة السياق).
</ResponseField>

<ResponseField name="outputTokenLimit" type="integer">
  الحد الأقصى لرموز الإخراج `output tokens`.
</ResponseField>

<ResponseField name="supportedGenerationMethods" type="array">
  قائمة بطرق التوليد المدعومة (على سبيل المثال، `generateContent` ،`countTokens` ،`embedContent`).
</ResponseField>

<RequestExample>
```bash cURL
curl "https://api.lemondata.cc/v1beta/models/gemini-2.5-pro"
```

```python Python
import google.generativeai as genai

genai.configure(
    api_key="sk-your-api-key",
    transport="rest",
    client_options={"api_endpoint": "api.lemondata.cc"}
)

model = genai.get_model("models/gemini-2.5-pro")
print(f"Name: {model.name}")
print(f"Input limit: {model.input_token_limit}")
print(f"Output limit: {model.output_token_limit}")
```
</RequestExample>

<ResponseExample>
```json Response
{
  "name": "models/gemini-2.5-pro",
  "version": "1.0",
  "displayName": "gemini-2.5-pro",
  "description": "gemini-2.5-pro model available via LemonData",
  "inputTokenLimit": 1048576,
  "outputTokenLimit": 65536,
  "supportedGenerationMethods": ["generateContent", "countTokens"],
  "temperature": 1.0,
  "topP": 0.95,
  "topK": 40,
  "maxTemperature": 2.0
}
```
</ResponseExample>