---
title: "✨ Upstream Prompt Cache"
description: "Verstehen Sie das Prompt-Caching auf Provider-Ebene und wie es Kosten senkt"
---

## Übersicht

Zusätzlich zum [semantischen Plattform-Cache](/guides/caching) von LemonData bieten viele AI-Provider ihre eigene **Prompt-Caching**-Funktion an. Dies ist ein separater Caching-Mechanismus, der auf Provider-Ebene (Anthropic, OpenAI, DeepSeek usw.) arbeitet.

<Note>
**Zwei Arten von Caching**

| Typ | Ort | Funktionsweise | Kosten |
|------|-------|--------------|------|
| **Plattform-Cache** | LemonData | Semantischer Ähnlichkeitsabgleich | 10 % des normalen Preises |
| **Provider-Cache** | Upstream (Anthropic/OpenAI/etc) | Exakter Präfix-Abgleich | Ermäßigte Token-Raten |

Diese schließen sich **gegenseitig aus**: Wenn der Plattform-Cache trifft, erfolgt kein Upstream-Aufruf, sodass der Provider-Cache nicht angewendet wird.
</Note>

## Wie Provider-Prompt-Caching funktioniert

Provider-Prompt-Caching speichert die verarbeitete Darstellung Ihres Prompt-Präfixes auf den Servern des Providers. Wenn Sie eine Anfrage mit demselben Präfix senden, kann der Provider die erneute Verarbeitung dieser Token überspringen.

### Hauptmerkmale

- **Präfix-basiert**: Nur der Anfang Ihres Prompts kann zwischengespeichert werden
- **Exakte Übereinstimmung**: Erfordert identische Token (keine semantische Ähnlichkeit)
- **Zeitlich begrenzt**: Cache-Einträge laufen ab (normalerweise 5–60 Minuten)
- **Automatisch**: Keine spezielle Konfiguration erforderlich

```
Anfrage 1: [System-Prompt + Kontext A + Frage 1]
           ^^^^^^^^^^^^^^^^^^^^^^^^
           Dieses Präfix wird zwischengespeichert

Anfrage 2: [System-Prompt + Kontext A + Frage 2]
           ^^^^^^^^^^^^^^^^^^^^^^^^
           Cache-Treffer! Nur Frage 2 wird verarbeitet
```

## Unterstützte Provider

| Provider | Cache-Lese-Rabatt | Cache-Schreib-Kosten | Min. Token |
|----------|---------------------|------------------|------------|
| **Anthropic** | 90 % Rabatt | 25 % Aufpreis | 1024 |
| **OpenAI** | 50 % Rabatt | Gleich wie Input | 1024 |
| **DeepSeek** | 90 % Rabatt | Gleich wie Input | 64 |
| **Google** | 75 % Rabatt | 25 % Aufpreis | 32768 |

<Info>
Rabatte werden automatisch angewendet. LemonData gibt die Cache-Preise des Providers direkt an Sie weiter.
</Info>

## Cache-Nutzung erkennen

### In den Nutzungsprotokollen

Ihre Nutzungsprotokolle zeigen eine detaillierte Aufschlüsselung der Cache-Token:

| Feld | Beschreibung |
|-------|-------------|
| `cacheReadTokens` | Token aus dem Provider-Cache (ermäßigt) |
| `cacheWriteTokens` | Token, die in den Cache geschrieben wurden (für zukünftige Anfragen) |
| `nonCachedPromptTokens` | Token, die ohne Cache verarbeitet wurden |

### In Transaktionen

Transaktionen zeigen ein **Provider Cache**-Label an, wenn Upstream-Caching verwendet wurde:

- **Cache** (himmelblau): Plattform-Semantic-Cache-Treffer – 90 % Rabatt
- **Provider Cache** (blaugrün): Upstream-Prompt-Cache-Treffer – ermäßigte Raten

## Kostenberechnungsbeispiel

Für eine Anfrage mit 10.000 Input-Token an Claude (Anthropic):

**Ohne Cache:**
```
10.000 Token × $3,00/1M = $0,030
```

**Mit Provider-Cache (8.000 gecacht + 2.000 neu):**
```
Cache-Lesen:    8.000 Token × $0,30/1M = $0,0024  (90 % Rabatt)
Cache-Schreiben: 2.000 Token × $3,75/1M = $0,0075  (25 % Aufpreis)
Gesamt: $0,0099 (67 % Ersparnis)
```

## Best Practices

<AccordionGroup>
  <Accordion title="Konsistente System-Prompts verwenden">
    Platzieren Sie Ihren System-Prompt und statischen Kontext am Anfang Ihrer Nachrichten. Dies maximiert die Cache-Trefferwahrscheinlichkeit.
  </Accordion>

  <Accordion title="Ähnliche Anfragen bündeln">
    Senden Sie Anfragen mit demselben Präfix zeitnah hintereinander, um vom Cache zu profitieren, bevor er abläuft.
  </Accordion>

  <Accordion title="Mindest-Token-Anforderungen einhalten">
    Stellen Sie sicher, dass Ihr cachebarer Präfix die Mindestanforderung des Providers erfüllt (z. B. 1024 Token für Anthropic/OpenAI).
  </Accordion>

  <Accordion title="Cache-Metriken überwachen">
    Überprüfen Sie die Nutzungsstatistiken in Ihrem Dashboard auf Cache-Trefferraten und Einsparungen.
  </Accordion>
</AccordionGroup>

## Plattform-Cache vs. Provider-Cache

| Aspekt | Plattform-Cache | Provider-Cache |
|--------|----------------|----------------|
| **Abgleich** | Semantische Ähnlichkeit | Exakter Präfix-Abgleich |
| **Kosten** | 10 % des normalen Preises | Ermäßigte Raten |
| **Latenz** | Sofort (~1 ms) | Reduziert (Verarbeitung übersprungen) |
| **Steuerung** | Dashboard-Einstellungen | Automatisch |
| **Geltungsbereich** | Benutzerübergreifend (optional) | Pro API-Key |

### Wann welcher Cache greift

```
Anfrage eingehend
    │
    ▼
┌─────────────────────────┐
│ Plattform-Cache-Treffer?│
└─────────────────────────┘
    │ Ja                │ Nein
    ▼                   ▼
┌───────────┐    ┌─────────────────────────┐
│ Gecachte  │    │ Upstream-API aufrufen   │
│ Antwort   │    └─────────────────────────┘
│ (10 %)    │            │
└───────────┘            ▼
               ┌─────────────────────────┐
               │ Provider-Cache-Treffer? │
               └─────────────────────────┘
                   │ Ja          │ Nein
                   ▼             ▼
               Ermäßigte      Voller
               Token-Rate     Token-Preis
```

## Cache-Status prüfen

### Response-Header

```
X-Cache-Status: HIT           # Plattform-Cache-Treffer
X-Cache-Status: MISS          # Kein Plattform-Cache
X-Upstream-Cache-Read: 8000   # Provider-Cache gelesene Token
X-Upstream-Cache-Write: 2000  # Provider-Cache geschriebene Token
```

### Usage-API

Fragen Sie Ihre Nutzungsprotokolle ab, um die Cache-Aufschlüsselung zu sehen:

```bash
curl https://api.lemondata.cc/v1/usage/logs \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json"
```

Die Antwort enthält:
```json
{
  "promptTokens": 10000,
  "cacheReadTokens": 8000,
  "cacheWriteTokens": 2000,
  "nonCachedPromptTokens": 0,
  "completionTokens": 500,
  "cost": 0.0099
}
```

## FAQ

<AccordionGroup>
  <Accordion title="Kann ich Provider-Caching deaktivieren?">
    Provider-Caching ist automatisch und kann nicht deaktiviert werden. Es bringt Ihnen jedoch nur Vorteile (niedrigere Kosten), sodass es keinen Grund gibt, es zu deaktivieren.
  </Accordion>

  <Accordion title="Warum hat meine Anfrage den Provider-Cache nicht getroffen?">
    Häufige Gründe:
    - Präfix hat sich geändert (selbst ein Token Unterschied)
    - Cache abgelaufen (normalerweise 5–60 Minuten)
    - Präfix zu kurz (unter der Mindest-Token-Anzahl)
    - Anderer API-Key verwendet
  </Accordion>

  <Accordion title="Unterstützt BYOK Provider-Caching?">
    Ja! Wenn Sie Ihre eigenen API-Keys verwenden (BYOK), funktioniert Provider-Caching genauso. Der Cache ist an Ihren Upstream-API-Key gebunden.
  </Accordion>

  <Accordion title="Wie maximiere ich die Cache-Einsparungen?">
    1. Nutzen Sie den semantischen Plattform-Cache für wiederholte ähnliche Anfragen
    2. Strukturieren Sie Prompts mit statischem Inhalt am Anfang
    3. Halten Sie System-Prompts über Anfragen hinweg konsistent
    4. Senden Sie zusammenhängende Anfragen in schneller Folge
  </Accordion>
</AccordionGroup>
