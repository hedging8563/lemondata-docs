---
title: "Best Practices"
description: "Optimieren Sie Ihre LemonData API-Nutzung hinsichtlich Kosten, Leistung und Zuverlässigkeit"
---

## Modellauswahl

Die Wahl des richtigen Modells kann erhebliche Auswirkungen auf Kosten und Qualität haben.

### Aufgabenbasierte Empfehlungen

| Aufgabe | Empfohlene Modelle | Begründung |
|------|-------------------|-----------|
| **Einfache Q&A** | `gpt-4o-mini`, `gemini-2.5-flash` | Schnell, günstig, ausreichend |
| **Komplexes logisches Denken** | `o3`, `claude-opus-4-5`, `deepseek-r1` | Bessere Logik und Planung |
| **Programmierung** | `claude-sonnet-4-5`, `gpt-4o`, `deepseek-v3.2` | Optimiert für Code |
| **Kreatives Schreiben** | `claude-sonnet-4-5`, `gpt-4o` | Bessere Prosaqualität |
| **Vision/Bilder** | `gpt-4o`, `claude-sonnet-4-5`, `gemini-2.5-flash` | Native Vision-Unterstützung |
| **Langer Kontext** | `gemini-2.5-pro`, `claude-sonnet-4-5` | 1M+ Token-Fenster |
| **Kostenbewusst** | `gpt-4o-mini`, `gemini-2.5-flash`, `deepseek-v3.2` | Bestes Preis-Leistungs-Verhältnis |

### Kostenstufen

```
$$$$ Premium: o3, claude-opus-4-5, gpt-4o
$$$  Standard: claude-sonnet-4-5, gpt-4o
$$   Budget:   gpt-4o-mini, gemini-2.5-flash
$    Economy:  deepseek-v3.2, deepseek-r1
```

## Kostenoptimierung

### 1. Kleinere Modelle zuerst verwenden

```python
def smart_query(question: str, complexity: str = "auto"):
    """Nutzen Sie günstigere Modelle für einfache Aufgaben."""

    if complexity == "simple":
        model = "gpt-4o-mini"
    elif complexity == "complex":
        model = "gpt-4o"
    else:
        # Günstig starten, bei Bedarf eskalieren
        model = "gpt-4o-mini"

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": question}]
    )
    return response
```

### 2. max_tokens festlegen

Legen Sie immer ein angemessenes `max_tokens`-Limit fest:

```python
# ❌ Schlecht