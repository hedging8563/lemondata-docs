---
title: "Nachricht erstellen"
api: "POST /v1/messages"
description: "Erstellt eine Nachricht im Format der Anthropic Messages API"
---

## Übersicht

Dieser Endpunkt bietet native Kompatibilität mit der Anthropic Messages API. Verwenden Sie diesen für Claude-Modelle mit Funktionen wie Extended Thinking.

<Note>
Basis-URL für das Anthropic SDK: `https://api.lemondata.cc` (kein `/v1` Suffix)
</Note>

## Request-Header

<ParamField header="x-api-key" type="string" required>
  Ihr LemonData API-Key. Alternative zum Bearer-Token.
</ParamField>

<ParamField header="anthropic-version" type="string" required>
  Anthropic API-Version. Verwenden Sie `2023-06-01`.
</ParamField>

## Request-Body

<ParamField body="model" type="string" required>
  Claude-Modell-ID (z. B. `claude-sonnet-4-5`).
</ParamField>

<ParamField body="messages" type="array" required>
  Array von Nachrichtenobjekten mit `role` und `content`.
</ParamField>

<ParamField body="max_tokens" type="integer" required>
  Maximale Anzahl an zu generierenden Tokens.
</ParamField>

<ParamField body="system" type="string">
  System-Prompt (getrennt vom messages-Array).
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Sampling-Temperatur (0-1).
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Streaming-Antworten aktivieren.
</ParamField>

<ParamField body="thinking" type="object">
  Konfiguration für Extended Thinking (Claude Opus 4.5).

  - `type` (string): `"enabled"` zum Aktivieren
  - `budget_tokens` (integer): Token-Budget für das Thinking
</ParamField>

<ParamField body="tools" type="array">
  Verfügbare Tools für das Modell.
</ParamField>

<ParamField body="tool_choice" type="object">
  Wie das Modell Tools verwenden soll. Optionen: `auto`, `any`, `tool` (spezifisches Tool).
</ParamField>

<ParamField body="top_p" type="number">
  Nucleus-Sampling-Parameter. Verwenden Sie entweder temperature oder top_p, nicht beides.
</ParamField>

<ParamField body="top_k" type="integer">
  Nur aus den Top-K-Optionen für jedes Token sampeln.
</ParamField>

<ParamField body="stop_sequences" type="array">
  Benutzerdefinierte Stop-Sequenzen, die das Modell veranlassen, die Generierung zu beenden.
</ParamField>

<ParamField body="metadata" type="object">
  Metadaten, die der Anfrage zu Tracking-Zwecken beigefügt werden.
</ParamField>

## Response

<ResponseField name="id" type="string">
  Eindeutige Nachrichten-ID.
</ResponseField>

<ResponseField name="type" type="string">
  Immer `message`.
</ResponseField>

<ResponseField name="role" type="string">
  Immer `assistant`.
</ResponseField>

<ResponseField name="content" type="array">
  Array von Inhaltsblöcken (text, thinking, tool_use).
</ResponseField>

<ResponseField name="model" type="string">
  Verwendetes Modell.
</ResponseField>

<ResponseField name="stop_reason" type="string">
  Grund, warum die Generierung gestoppt wurde (`end_turn`, `max_tokens`, `tool_use`).
</ResponseField>

<ResponseField name="usage" type="object">
  Token-Verbrauch mit `input_tokens` und `output_tokens`.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/messages" \
  -H "x-api-key: sk-your-api-key" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "max_tokens": 1024,
    "system": "You are a helpful assistant.",
    "messages": [
      {"role": "user", "content": "Hello, Claude!"}
    ]
  }'
```

```python Python
from anthropic import Anthropic

client = Anthropic(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc"
)

message = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1024,
    system="You are a helpful assistant.",
    messages=[
        {"role": "user", "content": "Hello, Claude!"}
    ]
)

print(message.content[0].text)
```

```javascript JavaScript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc'
});

const message = await client.messages.create({
  model: 'claude-sonnet-4-5',
  max_tokens: 1024,
  system: 'You are a helpful assistant.',
  messages: [
    { role: 'user', content: 'Hello, Claude!' }
  ]
});

console.log(message.content[0].text);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model":      "claude-sonnet-4-5",
        "max_tokens": 1024,
        "system":     "You are a helpful assistant.",
        "messages": []map[string]string{
            {"role": "user", "content": "Hello, Claude!"},
        },
    }

    jsonData, _ := json.Marshal(payload)
    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/messages", bytes.NewBuffer(jsonData))
    req.Header.Set("x-api-key", "sk-your-api-key")
    req.Header.Set("anthropic-version", "2023-06-01")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    body, _ := io.ReadAll(resp.Body)
    fmt.Println(string(body))
}
```

```php PHP
<?php
$payload = [
    'model' => 'claude-sonnet-4-5',
    'max_tokens' => 1024,
    'system' => 'You are a helpful assistant.',
    'messages' => [
        ['role' => 'user', 'content' => 'Hello, Claude!']
    ]
];

$ch = curl_init('https://api.lemondata.cc/v1/messages');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'x-api-key: sk-your-api-key',
        'anthropic-version: 2023-06-01',
        'Content-Type: application/json'
    ],
    CURLOPT_POSTFIELDS => json_encode($payload)
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
echo $data['content'][0]['text'];
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "msg_abc123",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you today?"
    }
  ],
  "model": "claude-sonnet-4-5",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 15,
    "output_tokens": 10
  }
}
```
</ResponseExample>

## Beispiel für Extended Thinking

```python
message = client.messages.create(
    model="claude-opus-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    messages=[{"role": "user", "content": "Solve this math problem..."}]
)

for block in message.content:
    if block.type == "thinking":
        print(f"Thinking: {block.thinking}")
    elif block.type == "text":
        print(f"Response: {block.text}")
```