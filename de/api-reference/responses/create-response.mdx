---
title: "Response erstellen"
api: "POST /v1/responses"
description: "Erstellt eine Response unter Verwendung des OpenAI Responses API-Formats"
---

Die Responses API ist die neuere zustandsbehaftete Konversations-API von OpenAI. LemonData unterstützt dieses Format für kompatible Modelle.

## Request Body

<ParamField body="model" type="string" required>
  ID des zu verwendenden Modells. Siehe [Models](https://lemondata.cc/de/models) für verfügbare Optionen.
</ParamField>

<ParamField body="input" type="array" required>
  Eine Liste von Eingabeelementen, aus denen die Konversation besteht.

  Jedes Element kann sein:
  - `message`: Eine Konversationsnachricht mit Rolle und Inhalt
  - `function_call`: Eine Funktionsaufrufanfrage
  - `function_call_output`: Ausgabe eines Funktionsaufrufs
</ParamField>

<ParamField body="instructions" type="string">
  Systemanweisungen für das Modell (entspricht der Systemnachricht).
</ParamField>

<ParamField body="max_output_tokens" type="integer">
  Maximale Anzahl der zu generierenden Token.
</ParamField>

<ParamField body="temperature" type="number" default="1">
  Sampling-Temperatur zwischen 0 und 2.
</ParamField>

<ParamField body="tools" type="array">
  Eine Liste von Tools, die das Modell aufrufen kann.
</ParamField>

<ParamField body="stream" type="boolean" default="false">
  Wenn true, wird ein Stream von Ereignissen zurückgegeben.
</ParamField>

<ParamField body="previous_response_id" type="string">
  ID einer vorherigen Response, um die Konversation fortzusetzen.
</ParamField>

<ParamField body="store" type="boolean" default="true">
  Gibt an, ob die Response für einen späteren Abruf gespeichert werden soll.
</ParamField>

<ParamField body="metadata" type="object">
  Metadaten, die der Response zu Tracking-Zwecken beigefügt werden.
</ParamField>

<ParamField body="text" type="object">
  Konfigurationsoptionen für die Textgenerierung.
</ParamField>

<ParamField body="parallel_tool_calls" type="boolean" default="true">
  Gibt an, ob mehrere Tool-Aufrufe parallel zulässig sind.
</ParamField>

<ParamField body="top_p" type="number">
  Nucleus-Sampling-Parameter (0-1).
</ParamField>

<ParamField body="reasoning" type="object">
  Reasoning-Konfiguration für o1/o3-Modelle.

  - `effort` (string): Reasoning-Aufwandsebene (`low`, `medium`, `high`)
</ParamField>

## Response

<ResponseField name="id" type="string">
  Eindeutiger Identifikator für die Response.
</ResponseField>

<ResponseField name="object" type="string">
  Immer `response`.
</ResponseField>

<ResponseField name="created_at" type="integer">
  Unix-Zeitstempel des Zeitpunkts, an dem die Response erstellt wurde.
</ResponseField>

<ResponseField name="output" type="array">
  Liste der vom Modell generierten Ausgabeelemente.
</ResponseField>

<ResponseField name="usage" type="object">
  Token-Nutzungsstatistiken.
</ResponseField>

<RequestExample>
```bash cURL
curl -X POST "https://api.lemondata.cc/v1/responses" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"type": "message", "role": "user", "content": "Hello!"}
    ],
    "max_output_tokens": 1000
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-api-key",
    base_url="https://api.lemondata.cc/v1"
)

response = client.responses.create(
    model="gpt-4o",
    input=[
        {"type": "message", "role": "user", "content": "Hello!"}
    ],
    max_output_tokens=1000
)

print(response.output)
```

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: 'sk-your-api-key',
  baseURL: 'https://api.lemondata.cc/v1'
});

const response = await client.responses.create({
  model: 'gpt-4o',
  input: [
    { type: 'message', role: 'user', content: 'Hello!' }
  ],
  max_output_tokens: 1000
});

console.log(response.output);
```

```go Go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

func main() {
    payload := map[string]interface{}{
        "model": "gpt-4o",
        "input": []map[string]interface{}{
            {"type": "message", "role": "user", "content": "Hello!"},
        },
        "max_output_tokens": 1000,
    }
    body, _ := json.Marshal(payload)

    req, _ := http.NewRequest("POST", "https://api.lemondata.cc/v1/responses", bytes.NewBuffer(body))
    req.Header.Set("Authorization", "Bearer sk-your-api-key")
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()

    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result["output"])
}
```

```php PHP
<?php
$ch = curl_init('https://api.lemondata.cc/v1/responses');

curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => [
        'Content-Type: application/json',
        'Authorization: Bearer sk-your-api-key'
    ],
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'gpt-4o',
        'input' => [
            ['type' => 'message', 'role' => 'user', 'content' => 'Hello!']
        ],
        'max_output_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
curl_close($ch);

$data = json_decode($response, true);
print_r($data['output']);
```
</RequestExample>

<ResponseExample>
```json Response
{
  "id": "resp_abc123",
  "object": "response",
  "created_at": 1706000000,
  "model": "gpt-4o",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "Hello! How can I help you today?"}
      ]
    }
  ],
  "usage": {
    "input_tokens": 10,
    "output_tokens": 12,
    "total_tokens": 22
  }
}
```
</ResponseExample>