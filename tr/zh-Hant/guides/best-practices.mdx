---
title: "En İyi Uygulamalar"
description: "Maliyet etkinliğini, performansı ve güvenilirliği artırmak için LemonData API kullanımınızı optimize edin"
---

## Model Seçimi

Doğru modeli seçmek maliyeti ve kaliteyi önemli ölçüde etkiler.

### Görev Bazlı Öneriler

| Görev | Önerilen Model | Neden |
|------|-------------------|-----------|
| **Basit Soru-Cevap** | `gpt-4o-mini`, `gemini-2.5-flash` | Hızlı, ucuz, yeterince iyi |
| **Karmaşık Akıl Yürütme** | `o3`, `claude-opus-4-5`, `deepseek-r1` | Daha iyi mantık ve planlama yetenekleri |
| **Kodlama** | `claude-sonnet-4-5`, `gpt-4o`, `deepseek-v3.2` | Kod için optimize edilmiş |
| **Yaratıcı Yazarlık** | `claude-sonnet-4-5`, `gpt-4o` | Daha iyi nesir kalitesi |
| **Görsel/Görüntü** | `gpt-4o`, `claude-sonnet-4-5`, `gemini-2.5-flash` | Yerel görsel desteği |
| **Uzun Bağlam** | `gemini-2.5-pro`, `claude-sonnet-4-5` | 1M+ token penceresi |
| **Maliyet Duyarlı** | `gpt-4o-mini`, `gemini-2.5-flash`, `deepseek-v3.2` | En iyi fiyat/performans oranı |

### Maliyet Kademeleri

```
$$$$ Premium: o3, claude-opus-4-5, gpt-4o
$$$  Standard: claude-sonnet-4-5, gpt-4o
$$   Budget:   gpt-4o-mini, gemini-2.5-flash
$    Economy:  deepseek-v3.2, deepseek-r1
```

## Maliyet Optimizasyonu

### 1. Küçük Modellere Öncelik Verin

```python
def smart_query(question: str, complexity: str = "auto"):
    """Use cheaper models for simple tasks."""

    if complexity == "simple":
        model = "gpt-4o-mini"
    elif complexity == "complex":
        model = "gpt-4o"
    else:
        # Start cheap, escalate if needed
        model = "gpt-4o-mini"

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": question}]
    )
    return response
```

### 2. max_tokens Ayarlayın

Her zaman makul bir `max_tokens` sınırı belirleyin:

```python
# ❌ Yanlış: Sınır belirlenmedi, binlerce token üretilebilir
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Summarize this article"}]
)

# ✅ Doğru: Yanıt uzunluğunu sınırlayın
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Summarize this article"}],
    max_tokens=500  # Özet için makul sınır
)
```

### 3. Prompt'u Optimize Edin

```python
# ❌ Uzun prompt (daha fazla input token tüketir)
prompt = """
I would like you to please help me by analyzing the following text
and providing a comprehensive summary of the main points. Please be
thorough but also concise in your response. The text is as follows:
{text}
"""

# ✅ Kısa ve öz prompt (daha az token tüketir)
prompt = "Summarize the key points:\n{text}"
```

### 4. Önbelleğe Almayı Etkinleştirin

[Semantik Önbellekleme](/guides/caching) özelliğinden yararlanın:

```python
# 對於重複的相似查詢，快取可大幅節省成本
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What is machine learning?"}],
    temperature=0  # Belirlenimcilik = daha iyi önbellek isabet oranı
)
```

### 5. Benzer İstekleri Toplu İşleyin

```python
# ❌ Birçok küçük istek
for question in questions:
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": question}]
    )

# ✅ Daha az sayıda büyük istek
combined_prompt = "\n".join([f"{i+1}. {q}" for i, q in enumerate(questions)])
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": f"Answer each question:\n{combined_prompt}"}]
)
```

## Performans Optimizasyonu

### 1. Kullanıcı Deneyimini Artırmak İçin Akış (Streaming) Kullanın

Akış, algılanan performansı artırabilir:

```python
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Write a long essay"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### 2. Etkileşimli Kullanımlar İçin Hızlı Modeller Seçin

| Kullanım Senaryosu | Önerilen Model | Gecikme |
|----------|-------------|---------|
| Sohbet Arayüzü | `gpt-4o-mini`, `gemini-2.5-flash` | İlk token yaklaşık 200ms |
| Otomatik Tamamlama | `claude-haiku-4-5` | İlk token yaklaşık 150ms |
| Arka Plan İşleme | `gpt-4o`, `claude-sonnet-4-5` | İlk token yaklaşık 500ms |

### 3. Zaman Aşımı (Timeouts) Ayarlayın

```python
client = OpenAI(
    api_key="sk-your-key",
    base_url="https://api.lemondata.cc/v1",
    timeout=60.0  # 60 saniye zaman aşımı
)
```

## Güvenilirlik

### 1. Yeniden Deneme Mekanizması Uygulayın

```python
import time
from openai import RateLimitError, APIError

def chat_with_retry(messages, max_retries=3):
    for attempt in range(max_retries):
        try:
            return client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
        except RateLimitError:
            wait = 2 ** attempt
            print(f"Rate limited, waiting {wait}s...")
            time.sleep(wait)
        except APIError as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(1)
    raise Exception("Max retries exceeded")
```

### 2. Hataları Zarif Bir Şekilde Yönetin

```python
from openai import APIError, AuthenticationError, RateLimitError

try:
    response = client.chat.completions.create(...)
except AuthenticationError:
    # API key'i kontrol edin
    notify_admin("Invalid API key")
except RateLimitError:
    # Daha sonra işlemek üzere kuyruğa ekleyin veya yedek kullanın
    add_to_queue(request)
except APIError as e:
    if e.status_code == 402:
        notify_admin("Balance low")
    elif e.status_code >= 500:
        # Sunucu hatası, daha sonra tekrar deneyin
        schedule_retry(request)
```

### 3. Yedek Modeller (Fallback Models) Kullanın

```python
FALLBACK_CHAIN = ["gpt-4o", "claude-sonnet-4-5", "gemini-2.5-flash"]

def chat_with_fallback(messages):
    for model in FALLBACK_CHAIN:
        try:
            return client.chat.completions.create(
                model=model,
                messages=messages
            )
        except APIError:
            continue
    raise Exception("All models failed")
```

## Güvenlik

### 1. API Key'i Koruyun

```python
# ❌ Anahtarı asla kodun içine gömmeyin
client = OpenAI(api_key="sk-abc123...")

# ✅ Ortam değişkenlerini kullanın
import os
client = OpenAI(api_key=os.environ["LEMONDATA_API_KEY"])
```

### 2. Kullanıcı Girişini Doğrulayın

```python
def validate_message(content: str) -> bool:
    """API'ye göndermeden önce kullanıcı girişini doğrulayın."""
    if len(content) > 100000:
        raise ValueError("Message too long")
    # Gerektiğinde diğer doğrulamaları ekleyin
    return True
```

### 3. API Key Sınırlarını Belirleyin

Aşağıdaki amaçlar için harcama limitli bağımsız API Key'ler oluşturun:
- Geliştirme/Test
- Üretim (Production) ortamı
- Farklı uygulamalar

## İzleme

### 1. Kullanımı Takip Edin

Aşağıdakileri anlamak için kontrol panelinizi düzenli olarak kontrol edin:
- Modellere göre token kullanımı
- Maliyet dökümü
- Önbellek isabet oranı
- Hata oranları

### 2. Önemli Metrikleri Kaydedin

```python
import logging

response = client.chat.completions.create(...)

logging.info({
    "model": response.model,
    "prompt_tokens": response.usage.prompt_tokens,
    "completion_tokens": response.usage.completion_tokens,
    "total_tokens": response.usage.total_tokens,
})
```

### 3. Uyarılar Ayarlayın

Hizmet kesintilerini önlemek için kontrol panelinde düşük bakiye uyarıları yapılandırın.

## Kontrol Listesi

<AccordionGroup>
  <Accordion title="Maliyet Optimizasyonu">
    - [ ] Her görev için uygun modeli kullanın
    - [ ] max_tokens sınırlarını ayarlayın
    - [ ] Prompt'ları kısa ve öz tutun
    - [ ] Uygun yerlerde önbelleğe almayı etkinleştirin
    - [ ] Benzer istekleri toplu işleyin
  </Accordion>

  <Accordion title="Performans">
    - [ ] Etkileşimli deneyimler için akış kullanın
    - [ ] Gerçek zamanlı kullanımlar için hızlı modeller kullanın
    - [ ] Zaman aşımı ayarları yapılandırıldı
  </Accordion>

  <Accordion title="Güvenilirlik">
    - [ ] Yeniden deneme mantığı uygulandı
    - [ ] Hata yönetimi hazır
    - [ ] Yedek modeller yapılandırıldı
  </Accordion>

  <Accordion title="Güvenlik">
    - [ ] API Key ortam değişkenlerinde saklanıyor
    - [ ] Giriş doğrulaması
    - [ ] Geliştirme/Üretim için bağımsız anahtarlar kullanın
    - [ ] Harcama limitleri belirlendi
  </Accordion>
</AccordionGroup>