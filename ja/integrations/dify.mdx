---
title: "Dify"
description: "LLMアプリケーション構築のためにLemonDataをDifyと統合する"
---

## 概要

Difyは、オープンソースのLLMアプリケーション開発プラットフォームです。ビジュアルなプロンプトオーケストレーション、RAGパイプライン、エージェントフレームワーク、およびLLMOps機能を提供します。LemonDataは、Difyのカスタムモデルプロバイダーとして設定できます。

## メリット

- 1つのインターフェースで300以上のAIモデルにアクセス
- アプリケーションロジックを変更せずにモデルを切り替え
- 各タスクに最適なモデルを選択することでコストを最適化
- 一元化された請求と使用状況の追跡

## 前提条件

- APIアクセス権を持つLemonDataアカウント
- Difyのインストール（クラウドまたはセルフホスト）

## 設定手順

### ステップ 1: APIキーの取得

1. [LemonData Dashboard](https://lemondata.cc/dashboard)にログインします
2. [API Keys](https://lemondata.cc/dashboard/api)に移動します
3. APIキーを作成してコピーします（形式: `sk-...`）

### ステップ 2: カスタムモデルプロバイダーの追加

<Steps>
  <Step title="設定を開く">
    Difyで、**Settings** → **Model Provider**に移動します
  </Step>
  <Step title="OpenAI互換プロバイダーの追加">
    **Add Model Provider**をクリックし、**OpenAI-API-compatible**を選択します
  </Step>
  <Step title="プロバイダーの設定">
    以下の設定を入力します：

    | フィールド | 値 |
    |-------|-------|
    | プロバイダー名 | LemonData |
    | API Key | `sk-your-lemondata-key` |
    | API Base URL | `https://api.lemondata.cc/v1` |
  </Step>
  <Step title="モデルの追加">
    使用したいモデルを追加します：
    - `gpt-4o`
    - `gpt-4o-mini`
    - `claude-sonnet-4-5`
    - `claude-opus-4-5`
    - `gemini-2.5-flash`
    - `gemini-2.5-pro`
    - `deepseek-r1`
  </Step>
</Steps>

### ステップ 3: 接続テスト

1. モデルを選択します（例: `gpt-4o-mini`）
2. テストメッセージを送信します
3. レスポンスを受信することを確認します

## アプリケーションでの使用

### チャットボット

1. 新しいチャットボットアプリケーションを作成します
2. モデルプロバイダーとしてLemonDataを選択します
3. 好みのモデルを選択します
4. システムプロンプトとパラメータを設定します

### エージェント

1. 新しいエージェントアプリケーションを作成します
2. 能力の高いモデル（GPT-4o、Claude）を選択します
3. ツールとナレッジベースを追加します
4. エージェントの動作を設定します

### ワークフロー

1. ワークフローを作成します
2. LLMノードを追加します
3. 各ノードにLemonDataモデルを選択します
4. ノードを接続し、データフローを設定します

## 利用可能なモデル

| カテゴリ | モデル |
|----------|--------|
| チャット | GPT-4o, GPT-4o-mini, Claude Sonnet/Opus, Gemini, DeepSeek |
| 埋め込み | text-embedding-3-small, text-embedding-3-large |
| ビジョン | GPT-4o (画像対応), Claude Sonnet (画像対応) |

## RAGの設定

RAGアプリケーションの場合は、埋め込みを設定します：

1. **Settings** → **Model Provider**に移動します
2. 埋め込みモデルを追加します: `text-embedding-3-small`
3. ナレッジベースの設定でデフォルトの埋め込みモデルとして設定します

## ベストプラクティス

<AccordionGroup>
  <Accordion title="経済的なモデルから始める">
    テストと開発にはGPT-4o-miniを使用し、本番環境ではより強力なモデルに切り替えます。
  </Accordion>

  <Accordion title="モデルルーティングの使用">
    タスクごとに異なるモデルを設定します。単純なクエリには高速なモデルを、複雑な推論には強力なモデルを使用します。
  </Accordion>

  <Accordion title="使用状況の監視">
    DifyのLLMOps機能とLemonDataダッシュボードを併用して、コストとパフォーマンスを追跡します。
  </Accordion>
</AccordionGroup>

## トラブルシューティング

<AccordionGroup>
  <Accordion title="接続エラー">
    - API Base URLが正確に `https://api.lemondata.cc/v1` であることを確認してください
    - 末尾のスラッシュを確認してください
    - ネットワーク接続を確認してください
  </Accordion>

  <Accordion title="401 Unauthorized（認証エラー）">
    - APIキーを再確認してください
    - LemonDataダッシュボードでキーが有効であることを確認してください
  </Accordion>

  <Accordion title="モデルが見つかりません">
    - モデル名が正確に一致しているか確認してください
    - [lemondata.cc/en/models](https://lemondata.cc/ja/models) でモデルの利用可能性を確認してください
  </Accordion>
</AccordionGroup>