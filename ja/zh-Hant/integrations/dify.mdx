---
title: "Dify"
description: "LemonDataをDifyと統合してLLMアプリケーションを構築する"
---

## 概要

Difyは、オープンソースのLLMアプリケーション開発プラットフォームです。ビジュアルなPromptオーケストレーション、RAGパイプライン、Agentフレームワーク、およびLLMOps機能を提供します。LemonDataは、Dify内のカスタムモデルプロバイダーとして設定できます。

## メリット

- 単一のインターフェースを介して300以上のAIモデルにアクセス
- アプリケーションロジックを変更せずにモデルを切り替え
- 各タスクに最適なモデルを選択してコストを最適化
- 統合された請求と使用状況の追跡

## 前提条件

- APIアクセス権限を持つLemonDataアカウント
- Difyのインストール（クラウド版またはセルフホスト版）

## 設定手順

### ステップ 1：APIキーの取得

1. [LemonData Dashboard](https://lemondata.cc/dashboard)にログインします
2. [API Keys](https://lemondata.cc/dashboard/api)に移動します
3. APIキーを作成してコピーします（形式：`sk-...`）

### ステップ 2：カスタムモデルプロバイダーの追加

<Steps>
  <Step title="設定を開く">
    Difyで、**Settings** → **Model Provider**に移動します
  </Step>
  <Step title="OpenAI互換プロバイダーの追加">
    **Add Model Provider**をクリックし、**OpenAI-API-compatible**を選択します
  </Step>
  <Step title="プロバイダーの設定">
    以下の設定を入力します：

    | 項目 | 値 |
    |-------|-------|
    | プロバイダー名 | LemonData |
    | API Key | `sk-your-lemondata-key` |
    | API Base URL | `https://api.lemondata.cc/v1` |
  </Step>
  <Step title="モデルの追加">
    使用したいモデルを追加します：
    - `gpt-4o`
    - `gpt-4o-mini`
    - `claude-sonnet-4-5`
    - `claude-opus-4-5`
    - `gemini-2.5-flash`
    - `gemini-2.5-pro`
    - `deepseek-r1`
  </Step>
</Steps>

### ステップ 3：接続テスト

1. モデルを選択します（例：`gpt-4o-mini`）
2. テストメッセージを送信します
3. 回答が届くことを確認します

## アプリケーションでの使用

### チャットボット (Chatbot)

1. 新しいChatbotアプリケーションを作成します
2. モデルプロバイダーとしてLemonDataを選択します
3. 好みのモデルを選択します
4. システムプロンプト (System Prompt) とパラメータを設定します

### エージェント (Agent)

1. Agentアプリケーションを作成します
2. 強力なモデル (GPT-4o, Claude) を選択します
3. ツールとナレッジベースを追加します
4. Agentの動作を設定します

### ワークフロー (Workflow)

1. ワークフローを作成します
2. LLMノードを追加します
3. 各ノードにLemonDataモデルを選択します
4. ノードを接続し、データフローを設定します

## 利用可能なモデル

| カテゴリ | モデル |
|----------|--------|
| チャット (Chat) | GPT-4o, GPT-4o-mini, Claude Sonnet/Opus, Gemini, DeepSeek |
| 埋め込み (Embeddings) | text-embedding-3-small, text-embedding-3-large |
| ビジョン (Vision) | GPT-4o (画像対応), Claude Sonnet (画像対応) |

## RAGの設定

RAGアプリケーションの場合は、埋め込みモデルを設定します：

1. **Settings** → **Model Provider**に移動します
2. 埋め込みモデルを追加します：`text-embedding-3-small`
3. ナレッジベースの設定で、これをデフォルトの埋め込みモデルに設定します

## ベストプラクティス

<AccordionGroup>
  <Accordion title="低コストモデルから始める">
    テストおよび開発段階ではGPT-4o-miniを使用し、本番環境ではより強力なモデルに切り替えます。
  </Accordion>

  <Accordion title="モデルルーティングの使用">
    タスクごとに異なるモデルを設定します。単純なクエリには高速なモデルを、複雑な推論には強力なモデルを使用します。
  </Accordion>

  <Accordion title="使用状況の監視">
    DifyのLLMOps機能とLemonDataコンソールを組み合わせて、コストとパフォーマンスを追跡します。
  </Accordion>
</AccordionGroup>

## トラブルシューティング

<AccordionGroup>
  <Accordion title="接続エラー">
    - API Base URLが正確に `https://api.lemondata.cc/v1` であることを確認してください
    - 末尾にスラッシュがあるか確認してください
    - ネットワーク接続を確認してください
  </Accordion>

  <Accordion title="401 未認証 (Unauthorized)">
    - APIキーを再確認してください
    - LemonDataコンソールでそのキーが有効であることを確認してください
  </Accordion>

  <Accordion title="モデルが見つからない">
    - モデル名が完全に一致していることを確認してください
    - [lemondata.cc/en/models](https://lemondata.cc/zh-TW/models) でモデルの利用可能性を確認してください
  </Accordion>
</AccordionGroup>