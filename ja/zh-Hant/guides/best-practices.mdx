---
title: "ベストプラクティス"
description: "LemonData API の利用を最適化し、コスト効率、パフォーマンス、信頼性を向上させます"
---

## モデルの選択

適切なモデルを選択することは、コストと品質に大きな影響を与えます。

### タスク別の推奨事項

| タスク | 推奨モデル | 理由 |
|------|-------------------|-----------|
| **シンプルな Q&A** | `gpt-4o-mini`, `gemini-2.5-flash` | 高速、安価、十分な性能 |
| **複雑な推論** | `o3`, `claude-opus-4-5`, `deepseek-r1` | より優れた論理と計画能力 |
| **コーディング** | `claude-sonnet-4-5`, `gpt-4o`, `deepseek-v3.2` | コードに最適化済み |
| **クリエイティブライティング** | `claude-sonnet-4-5`, `gpt-4o` | より高い文章品質 |
| **ビジョン / 画像** | `gpt-4o`, `claude-sonnet-4-5`, `gemini-2.5-flash` | ネイティブなビジョンサポート |
| **長いコンテキスト** | `gemini-2.5-pro`, `claude-sonnet-4-5` | 1M+ token ウィンドウ |
| **コスト重視** | `gpt-4o-mini`, `gemini-2.5-flash`, `deepseek-v3.2` | 最高のコストパフォーマンス |

### コスト階層

```
$$$$ Premium: o3, claude-opus-4-5, gpt-4o
$$$  Standard: claude-sonnet-4-5, gpt-4o
$$   Budget:   gpt-4o-mini, gemini-2.5-flash
$    Economy:  deepseek-v3.2, deepseek-r1
```

## コストの最適化

### 1. 小型モデルを優先的に使用する

```python
def smart_query(question: str, complexity: str = "auto"):
    """Use cheaper models for simple tasks."""

    if complexity == "simple":
        model = "gpt-4o-mini"
    elif complexity == "complex":
        model = "gpt-4o"
    else:
        # Start cheap, escalate if needed
        model = "gpt-4o-mini"

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": question}]
    )
    return response
```

### 2. max_tokens を設定する

適切な `max_tokens` 制限を必ず設定してください：

```python
# ❌ 錯誤：未設限制，可能會產生數千個 token
response = client